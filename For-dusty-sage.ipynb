{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extract mass and metallicity history from Dusty-SAGE output'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "import copy\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "cosmo = FlatLambdaCDM(H0=73, Om0=0.25)\n",
    "import matplotlib.patheffects as PathEffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from os.path import dirname, abspath, join as pjoin\n",
    "import Corrfunc\n",
    "from Corrfunc.theory.xi import xi\n",
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galdtype_dusty(align):\n",
    "     \n",
    "    '''Define the data-type for the public version of Dusty-SAGE'''\n",
    "    \n",
    "    Galdesc_full = [\n",
    "        ('SnapNum'                      , np.int32),\n",
    "        ('Type'                         , np.int32),\n",
    "        ('GalaxyIndex'                  , np.int64),\n",
    "        ('CentralGalaxyIndex'           , np.int64),\n",
    "        ('SAGEHaloIndex'                , np.int32),\n",
    "        ('SAGETreeIndex'                , np.int32),\n",
    "        ('SimulationHaloIndex'          , np.int64),\n",
    "        ('mergeType'                    , np.int32),\n",
    "        ('mergeIntoID'                  , np.int32),\n",
    "        ('mergeIntoSnapNum'             , np.int32),\n",
    "        ('dT'                           , np.float32),\n",
    "        ('Pos'                          , (np.float32, 3)),\n",
    "        ('Vel'                          , (np.float32, 3)),\n",
    "        ('Spin'                         , (np.float32, 3)),\n",
    "        ('Len'                          , np.int32),\n",
    "        ('Mvir'                         , np.float32),\n",
    "        ('CentralMvir'                  , np.float32),\n",
    "        ('Rvir'                         , np.float32),\n",
    "        ('Vvir'                         , np.float32),\n",
    "        ('Vmax'                         , np.float32),\n",
    "        ('VelDisp'                      , np.float32),\n",
    "        ('ColdGas'                      , np.float32),\n",
    "        ('f_H2'                         , np.float32),\n",
    "        ('f_HI'                         , np.float32),\n",
    "        ('cf'                           , np.float32),\n",
    "        ('Zp'                           , np.float32),\n",
    "        ('Pressure'                     , np.float32),\n",
    "        ('StellarMass'                  , np.float32),\n",
    "        ('BulgeMass'                    , np.float32),\n",
    "        ('BulgeInstability'             , np.float32),\n",
    "        ('HotGas'                       , np.float32),\n",
    "        ('EjectedMass'                  , np.float32),\n",
    "        ('BlackHoleMass'                , np.float32),\n",
    "        ('IntraClusterStars'            , np.float32),\n",
    "        ('MetalsColdGas'                , np.float32),\n",
    "        ('MetalsStellarMass'            , np.float32),\n",
    "        ('MetalsBulgeMass'              , np.float32),\n",
    "        ('MetalsHotGas'                 , np.float32),\n",
    "        ('MetalsEjectedMass'            , np.float32),\n",
    "        ('MetalsIntraClusterStars'      , np.float32),\n",
    "        ('ColdDust'                     , np.float32),\n",
    "        ('HotDust'                      , np.float32),\n",
    "        ('EjectedDust'                     , np.float32),\n",
    "        ('SfrDisk'                      , np.float32),\n",
    "        ('SfrBulge'                     , np.float32),\n",
    "        ('SfrDiskZ'                     , np.float32),\n",
    "        ('SfrBulgeZ'                    , np.float32),\n",
    "        ('SfrDiskDTG'                     , np.float32),\n",
    "        ('SfrBulgeDTG'                    , np.float32),\n",
    "        ('dustdotform'                  , np.float32),\n",
    "        ('dustdotgrowth'                    , np.float32),\n",
    "        ('dustdotdestruct'                    , np.float32),\n",
    "#        ('Sfr'                          , (np.float32, 64)),\n",
    "        ('DiskRadius'                   , np.float32),\n",
    "        ('Cooling'                      , np.float32),\n",
    "        ('Heating'                      , np.float32),\n",
    "        ('QuasarModeBHaccretionMass'    , np.float32),\n",
    "        ('TimeOfLastMajorMerger'         , np.float32),\n",
    "        ('TimeOfLastMinorMerger'         , np.float32),\n",
    "        ('OutflowRate'                  , np.float32),\n",
    "        ('infallMvir'                   , np.float32),\n",
    "        ('infallVvir'                   , np.float32),\n",
    "        ('infallVmax'                   , np.float32)\n",
    "        ]\n",
    "    names = [Galdesc_full[i][0] for i in range(len(Galdesc_full))]\n",
    "    formats = [Galdesc_full[i][1] for i in range(len(Galdesc_full))]\n",
    "    if(align==True):\n",
    "        Galdesc = np.dtype({'names':names, 'formats':formats}, align=True)\n",
    "    else:\n",
    "        Galdesc = np.dtype({'names':names, 'formats':formats})\n",
    "    return Galdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galdtype(align):\n",
    "    \n",
    "    '''Define the data-type for the public version of SAGE'''\n",
    "    \n",
    "    Galdesc_full = [\n",
    "        ('SnapNum'                      , np.int32),\n",
    "        ('Type'                         , np.int32),\n",
    "        ('GalaxyIndex'                  , np.int64),\n",
    "        ('CentralGalaxyIndex'           , np.int64),\n",
    "        ('SAGEHaloIndex'                , np.int32),\n",
    "        ('SAGETreeIndex'                , np.int32),\n",
    "        ('SimulationHaloIndex'          , np.int64),\n",
    "        ('mergeType'                    , np.int32),\n",
    "        ('mergeIntoID'                  , np.int32),\n",
    "        ('mergeIntoSnapNum'             , np.int32),\n",
    "        ('dT'                           , np.float32),\n",
    "        ('Pos'                          , (np.float32, 3)),\n",
    "        ('Vel'                          , (np.float32, 3)),\n",
    "        ('Spin'                         , (np.float32, 3)),\n",
    "        ('Len'                          , np.int32),\n",
    "        ('Mvir'                         , np.float32),\n",
    "        ('CentralMvir'                  , np.float32),\n",
    "        ('Rvir'                         , np.float32),\n",
    "        ('Vvir'                         , np.float32),\n",
    "        ('Vmax'                         , np.float32),\n",
    "        ('VelDisp'                      , np.float32),\n",
    "        ('ColdGas'                      , np.float32),\n",
    "        ('StellarMass'                  , np.float32),\n",
    "        ('BulgeMass'                    , np.float32),\n",
    "        ('HotGas'                       , np.float32),\n",
    "        ('EjectedMass'                  , np.float32),\n",
    "        ('BlackHoleMass'                , np.float32),\n",
    "        ('IntraClusterStars'            , np.float32),\n",
    "        ('MetalsColdGas'                , np.float32),\n",
    "        ('MetalsStellarMass'            , np.float32),\n",
    "        ('MetalsBulgeMass'              , np.float32),\n",
    "        ('MetalsHotGas'                 , np.float32),\n",
    "        ('MetalsEjectedMass'            , np.float32),\n",
    "        ('MetalsIntraClusterStars'      , np.float32),\n",
    "        ('SfrDisk'                      , np.float32),\n",
    "        ('SfrBulge'                     , np.float32),\n",
    "        ('SfrDiskZ'                     , np.float32),\n",
    "        ('SfrBulgeZ'                    , np.float32),\n",
    "        ('DiskRadius'                   , np.float32),\n",
    "        ('Cooling'                      , np.float32),\n",
    "        ('Heating'                      , np.float32),\n",
    "        ('QuasarModeBHaccretionMass'    , np.float32),\n",
    "        ('TimeOfLastMajorMerger'         , np.float32),\n",
    "        ('TimeOfLastMinorMerger'         , np.float32),\n",
    "        ('OutflowRate'                  , np.float32),\n",
    "        ('infallMvir'                   , np.float32),\n",
    "        ('infallVvir'                   , np.float32),\n",
    "        ('infallVmax'                   , np.float32)\n",
    "        ]\n",
    "    names = [Galdesc_full[i][0] for i in range(len(Galdesc_full))]\n",
    "    formats = [Galdesc_full[i][1] for i in range(len(Galdesc_full))]\n",
    "    if(align==True):\n",
    "        Galdesc = np.dtype({'names':names, 'formats':formats}, align=True)\n",
    "    else:\n",
    "        Galdesc = np.dtype({'names':names, 'formats':formats})\n",
    "    return Galdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_trees(SAM_option, directory, firstfile, lastfile):\n",
    "    '''\n",
    "    Iterating trees from the simulation output.\n",
    "    Currently, it can only read trees from SAGE (Croton et al. 2006, 2016)\n",
    "    and dusty-sage (Triani et al. 2020)\n",
    "    \n",
    "    Input:  - SAM option (int): (0) SAGE (1) Dusty-SAGE\n",
    "            - path of the directory containing simulation output (string).\n",
    "              Format of the simulation output: model_zX.XXX_Y\n",
    "              X.XXX : redshift of the snapshot\n",
    "              Y : file number\n",
    "    \n",
    "    Output: a tree, consist of properties of galaxies listed in galdtype_dusty() for Dusty SAGE or galdtype() for SAGE\n",
    "    '''\n",
    "    \n",
    "    #define variables\n",
    "    entries = [e for e in os.listdir(directory) \n",
    "               if os.path.isfile(os.path.join(directory, e))]\n",
    "    entries = [e for e in entries if e.startswith('model_z')]\n",
    "    redshift_strings = list(set([re.match(r'model_z(\\d+\\.?\\d*)_\\d+', e).group(1)\n",
    "                                for e in entries]))\n",
    "#    group_strings = list(set([re.match(r'model_z\\d+\\.?\\d*_(\\d+)', e).group(1)\n",
    "#                            for e in entries]))\n",
    "    \n",
    "#    group_strings.sort(key=lambda x: int(x))\n",
    "    redshift_strings.sort(key=lambda x: float(x), reverse=True)\n",
    "    \n",
    "    if SAM_option == 0:\n",
    "        Galdesc_false = galdtype(align=False)\n",
    "        Galdesc=galdtype(align=True)\n",
    "    elif SAM_option == 1:\n",
    "        Galdesc_false = galdtype_dusty(align=False)\n",
    "        Galdesc=galdtype_dusty(align=True)\n",
    "    else:\n",
    "        print(\"Choose a SAM: 0 - for SAGE, 1 - for Dusty-SAGE\")\n",
    "    \n",
    "    #open files\n",
    "    for group in range(firstfile, lastfile+1):\n",
    "#    for group in group_strings:\n",
    "        files = []\n",
    "        for redshift in redshift_strings:\n",
    "            fn = 'model_z%s_%s' % (redshift, group)\n",
    "            files.append(open(os.path.join(directory, fn), 'rb'))\n",
    "\n",
    "        n_trees = [np.fromfile(f, np.uint32, 1)[0] for f in files][0]\n",
    "        n_gals = [np.fromfile(f, np.uint32, 1)[0] for f in files]\n",
    "        chunk_sizes = [np.fromfile(f, np.uint32, n_trees) for f in files]\n",
    "        tree_sizes = sum(chunk_sizes, axis=0)\n",
    "        \n",
    "        for ii in range(n_trees):\n",
    "            tree_size = tree_sizes[ii]\n",
    "            tree = np.empty(tree_size, dtype=Galdesc_false)\n",
    "            offs=0\n",
    "            for jj in range(len(chunk_sizes)):\n",
    "                chunk_size = chunk_sizes[jj][ii]\n",
    "                if chunk_size <= 0: continue\n",
    "\n",
    "                data = np.fromfile(files[jj], Galdesc, chunk_size)\n",
    "\n",
    "                for _v in data.dtype.names:\n",
    "                    tree[_v][offs:offs+chunk_size] = data[_v]\n",
    "                offs += chunk_size\n",
    "\n",
    "            # First validate ID's.\n",
    "            for f in ['Type', 'GalaxyIndex', 'CentralGalaxyIndex']:\n",
    "                if min(tree[f]) < 0:\n",
    "                    print(\"ERROR; min(tree[{0}]) = {1} should be non-zero\"\n",
    "                            .format(f, min(tree[f])))\n",
    "                    raise ValueError()\n",
    "\n",
    "            # Validate central galaxy index (unique id, generated by sage)\n",
    "            ind = (np.where(tree['Type'] == 0))[0]\n",
    "            if not bool(np.all(tree['GalaxyIndex'][ind] == tree['CentralGalaxyIndex'][ind])):\n",
    "                print(\"tree[GalaxyIndex][ind] = {0}\".format(tree['GalaxyIndex'][ind]))\n",
    "                print(\"tree[CentralGalaxyIndex][ind] = {0}\".format(tree['CentralGalaxyIndex'][ind]))\n",
    "\n",
    "            assert bool(np.all(tree['GalaxyIndex'][ind] ==\n",
    "                            tree['CentralGalaxyIndex'][ind])), \\\n",
    "                \"Central Galaxy Index must equal Galaxy Index for centrals\"\n",
    "\n",
    "            yield tree\n",
    "            \n",
    "        for file in files:\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mass_and_metals(SAM_choice, tree, snap_limit):\n",
    "    \n",
    "    \"\"\"Calculate mass history from Dusty-SAGE tree.\n",
    "    In one fly, it will calculate the mass and metals history of a tree while mapping\n",
    "    the descendant.\n",
    "    \n",
    "    Input:  - SAM_choice (int): (0) SAGE (1) Dusty-SAGE\n",
    "            - a tree yielded by iterate_tree(directory)\n",
    "            - snap_limit (int) -- last snapshot of the tree\n",
    "    Output: 3-dimensions array.\n",
    "            1st array (NxM)*: Stellar mass history of the tree (in Msun/h)\n",
    "            2nd array (NxM)*: Stellar metallicity history (no unit)\n",
    "            \n",
    "            * N is the number of galaxies\n",
    "              M is the number of snapshot, ascending with increasing age of Universe.\n",
    "    \"\"\"\n",
    "    \n",
    "    recycle_fraction = 0.43\n",
    "    sorted_idx = np.argsort(tree, order=('GalaxyIndex', 'SnapNum'))\n",
    "    all_gal_ID = tree['GalaxyIndex']\n",
    "    snapshot_nr = tree['SnapNum']\n",
    "    merge_idx = tree['mergeIntoID']\n",
    "    merge_snapshot = tree['mergeIntoSnapNum']\n",
    "    merge_type = tree['mergeType']\n",
    "\n",
    "    delta_bulge = tree['SfrBulge'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "    delta_disk = tree['SfrDisk'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "    delta_mass = delta_bulge + delta_disk\n",
    "\n",
    "    \n",
    "    if SAM_choice == 0:\n",
    "        delta_bulge_metals = tree['SfrBulgeZ']  * tree['SfrBulge'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_disk_metals = tree['SfrDiskZ'] * tree['SfrDisk'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_metals = delta_bulge_metals + delta_disk_metals \n",
    "\n",
    "    elif SAM_choice == 1:\n",
    "        delta_bulge_metals = tree['SfrBulgeZ']  * tree['SfrBulge'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_disk_metals = tree['SfrDiskZ'] * tree['SfrDisk'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_bulge_dust = tree['SfrBulgeDTG'] * tree['SfrBulge'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_disk_dust = tree['SfrDiskDTG'] * tree['SfrDisk'] * tree['dT'] * 1.e6 * (1.0 - recycle_fraction)\n",
    "        delta_metals = delta_bulge_metals + delta_disk_metals + delta_bulge_dust + delta_disk_dust\n",
    "    else:\n",
    "        print(\"Choose a SAM: 0 - for SAGE, 1 - for Dusty-SAGE\")\n",
    "    \n",
    "    unique_ID = np.unique(all_gal_ID)\n",
    "    mass = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    metals = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    dust = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    \n",
    "    #map descendant and build mass and metal history\n",
    "    for kk, gal_ID in enumerate(unique_ID):\n",
    "        instant_mass = 0.0\n",
    "        instant_metals = 0.0\n",
    "        for ii, ID in enumerate(all_gal_ID[sorted_idx]):\n",
    "            if(gal_ID == ID):\n",
    "                instant_mass += delta_mass[sorted_idx[ii]] \n",
    "                mass[kk][snapshot_nr[sorted_idx[ii]]] = instant_mass\n",
    "                assert mass[kk][snapshot_nr[sorted_idx[ii]]] >= mass[kk][snapshot_nr[sorted_idx[ii-1]]]\n",
    "                \n",
    "                instant_metals += delta_metals[sorted_idx[ii]]\n",
    "                metals[kk][snapshot_nr[sorted_idx[ii]]] = instant_metals\n",
    "                assert metals[kk][snapshot_nr[sorted_idx[ii]]] >= metals[kk][snapshot_nr[sorted_idx[ii-1]]]\n",
    "                \n",
    "    \n",
    "    #make sure the mass and metals are increasing with snapshot_nr   \n",
    "    for i in range(len(unique_ID)):\n",
    "        for j in range(max(snapshot_nr)):\n",
    "            if (mass[i][j+1] < mass[i][j]):\n",
    "                mass[i][j+1] = mass[i][j]\n",
    "                \n",
    "            if (metals[i][j+1] < metals[i][j]):\n",
    "                metals[i][j+1] = metals[i][j]\n",
    "            \n",
    "    #identify merger and add mass\n",
    "    for snap in range(max(snapshot_nr)+1):\n",
    "        wsnap = np.where(snapshot_nr == snap)[0]\n",
    "        wmerge = np.where((merge_idx[wsnap] != -1) & (merge_snapshot[wsnap] < snap_limit) & (merge_type[wsnap] < 3))[0] #only include major (merge_type=1) and minor (merge_type=2) merger\n",
    "        merger_snap = merge_snapshot[wsnap][wmerge]\n",
    "        merger_id = merge_idx[wsnap][wmerge]\n",
    "        \n",
    "        if len(merger_id) > 0:\n",
    "            for i, idx in enumerate(merger_id):\n",
    "                \n",
    "                wmergesnap = np.where(snapshot_nr == merger_snap[i])[0]\n",
    "                central_ID = all_gal_ID[wmergesnap][idx]\n",
    "                central_idx = np.where(unique_ID[:,None] == central_ID)[0]\n",
    "                satellite_ID = all_gal_ID[wsnap][wmerge][i]\n",
    "                satellite_idx = np.where(unique_ID[:,None] == satellite_ID)[0]\n",
    "                \n",
    "                #added satellite mass to central mass\n",
    "                mass[central_idx] = mass[central_idx] + mass[satellite_idx]\n",
    "            \n",
    "                #eliminate the mass of satellite galaxies\n",
    "                mass[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                \n",
    "                #added satellite metals to central\n",
    "                metals[central_idx] = metals[central_idx] + metals[satellite_idx]\n",
    "                \n",
    "                #eliminate the metals of satellite galaxies\n",
    "                metals[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "               \n",
    "        #null more satellite (from mergetype 3 and 4)\n",
    "        wmerge = np.where((merge_idx[wsnap] != -1) & (merge_snapshot[wsnap] < snap_limit) & (merge_type[wsnap] > 2))[0]\n",
    "        merger_snap = merge_snapshot[wsnap][wmerge]\n",
    "        merger_id = merge_idx[wsnap][wmerge]\n",
    "        \n",
    "\n",
    "        if len(merger_id) > 0:\n",
    "            for i, idx in enumerate(merger_id):\n",
    "                wmergesnap = np.where(snapshot_nr == merger_snap[i])[0]\n",
    "                satellite_ID = all_gal_ID[wsnap][wmerge][i]\n",
    "                satellite_idx = np.where(unique_ID[:,None] == satellite_ID)[0]\n",
    "                \n",
    "                #eliminate the mass of satellite galaxies but don't add it to the central\n",
    "                mass[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                \n",
    "                #the metals as well\n",
    "                metals[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                \n",
    "\n",
    "        #Finally, divide total metals to total mass:\n",
    "        w = np.where((metals[:,snap] !=0) & (mass[:,snap] != 0))[0]\n",
    "        metals[w,snap] = metals[w,snap] / mass[w,snap]\n",
    "                \n",
    "    return mass, metals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dust_density (tree):\n",
    "    \"\"\"Calculate mass history from Dusty-SAGE tree.\n",
    "    In one fly, it will calculate the mass and metals history of a tree while mapping\n",
    "    the descendant.\n",
    "    \n",
    "    Input:  - SAM_choice (int): (0) SAGE (1) Dusty-SAGE\n",
    "            - a tree yielded by iterate_tree(directory)\n",
    "            - snap_limit (int) -- last snapshot of the tree\n",
    "    Output: 4 variable.\n",
    "            1st variable: Dust mass history (Msun/h)\n",
    "            2nd variable: Gas phase metal mass history (Msun/h)\n",
    "            3rd variable: Cold gas mass history (Msun/h)\n",
    "            4th variable: Disk scale radius history (Mpc/h)\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_idx = np.argsort(tree, order=('GalaxyIndex', 'SnapNum'))\n",
    "    all_gal_ID = tree['GalaxyIndex']\n",
    "    snapshot_nr = tree['SnapNum']\n",
    "    merge_idx = tree['mergeIntoID']\n",
    "    merge_snapshot = tree['mergeIntoSnapNum']\n",
    "    merge_type = tree['mergeType']\n",
    "    \n",
    "    instant_dust = tree['ColdDust'] * 1e10\n",
    "    instant_metals = tree['MetalsColdGas'] * 1e10\n",
    "    instant_gas = tree['ColdGas'] * 1e10\n",
    "    instant_rad = tree['DiskRadius'] #in Mpc\n",
    "    \n",
    "    unique_ID = np.unique(all_gal_ID)\n",
    "    dust = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    gas_metals = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    gas = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    rad = np.zeros((len(unique_ID), max(snapshot_nr)+1))\n",
    "    \n",
    "    #map descendant and build mass and metal history\n",
    "    for kk, gal_ID in enumerate(unique_ID):\n",
    "        for ii, ID in enumerate(all_gal_ID[sorted_idx]):\n",
    "            if(gal_ID == ID):\n",
    "                dust[kk][snapshot_nr[sorted_idx[ii]]] = instant_dust[sorted_idx[ii]]\n",
    "                gas_metals[kk][snapshot_nr[sorted_idx[ii]]] = instant_metals[sorted_idx[ii]]\n",
    "                gas[kk][snapshot_nr[sorted_idx[ii]]] = instant_gas[sorted_idx[ii]]\n",
    "                rad[kk][snapshot_nr[sorted_idx[ii]]] = instant_rad[sorted_idx[ii]]\n",
    "    \n",
    "    #identify merger and add mass\n",
    "    for snap in range(max(snapshot_nr)+1):\n",
    "        wsnap = np.where(snapshot_nr == snap)[0]\n",
    "        wmerge = np.where((merge_idx[wsnap] != -1) & (merge_snapshot[wsnap] < snap_limit) & (merge_type[wsnap] < 3))[0] #only include major (merge_type=1) and minor (merge_type=2) merger\n",
    "        merger_snap = merge_snapshot[wsnap][wmerge]\n",
    "        merger_id = merge_idx[wsnap][wmerge]\n",
    "        \n",
    "        if len(merger_id) > 0:\n",
    "            for i, idx in enumerate(merger_id):\n",
    "                \n",
    "                wmergesnap = np.where(snapshot_nr == merger_snap[i])[0]\n",
    "                central_ID = all_gal_ID[wmergesnap][idx]\n",
    "                central_idx = np.where(unique_ID[:,None] == central_ID)[0]\n",
    "                satellite_ID = all_gal_ID[wsnap][wmerge][i]\n",
    "                satellite_idx = np.where(unique_ID[:,None] == satellite_ID)[0]\n",
    "                \n",
    "                #eliminate the dust of satellite galaxies\n",
    "                dust[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                gas_metals[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                gas[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                rad[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "               \n",
    "        #null more satellite (from mergetype 3 and 4)\n",
    "        wmerge = np.where((merge_idx[wsnap] != -1) & (merge_snapshot[wsnap] < snap_limit) & (merge_type[wsnap] > 2))[0]\n",
    "        merger_snap = merge_snapshot[wsnap][wmerge]\n",
    "        merger_id = merge_idx[wsnap][wmerge]\n",
    "        \n",
    "\n",
    "        if len(merger_id) > 0:\n",
    "            for i, idx in enumerate(merger_id):\n",
    "                wmergesnap = np.where(snapshot_nr == merger_snap[i])[0]\n",
    "                satellite_ID = all_gal_ID[wsnap][wmerge][i]\n",
    "                satellite_idx = np.where(unique_ID[:,None] == satellite_ID)[0]\n",
    "                \n",
    "                #also the dust\n",
    "                dust[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                gas_metals[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                gas[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                rad[satellite_idx] = np.zeros(max(snapshot_nr)+1)\n",
    "                \n",
    "    return dust, gas_metals, gas, rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dust_history(SAM_choice, directory, firstfile, lastfile):\n",
    "    '''\n",
    "    Build mass and metallicity history from the output directory of dusty-sage\n",
    "    Input:  - SAM_choice (int): (0) SAGE (1) Dusty-SAGE\n",
    "            - directory (string) -- path to the directory containing dusty-sage output tree\n",
    "            - snap_limit (integer) -- number of last snapshot\n",
    "            \n",
    "    Output: - Dust (array(list(float))) -- an array containing a number of galaxy, each containing mass (in Msun/h) of each snapshot\n",
    "            - Gas metals (array(list(float))) -- an array containing a number of galaxy, each containing gas phase metal mass (in Msun/h) of each snapshot\n",
    "            - Gas (array(list(float))) -- an array containing a number of galaxy, each containing gas mass (in Msun/h) of each snapshot\n",
    "            - Rad (array(list(float))) -- an array containing a number of galaxy, each containing Disk Scale Radius (in Mpc/h) of each snapshot\n",
    "    '''\n",
    "    Dust = []\n",
    "    GasMetals = []\n",
    "    Gas = []\n",
    "    Rad = []\n",
    "    \n",
    "    for tree in iterate_trees(SAM_choice, directory, firstfile, lastfile):\n",
    "        dust, gas_metal, gas, rad = calculate_dust_density(tree)\n",
    "        Dust.extend(dust)\n",
    "        GasMetals.extend(gas_metal)\n",
    "        Gas.extend(gas)\n",
    "        Rad.extend(rad)\n",
    "\n",
    "    Dust = np.array(Dust)\n",
    "    GasMetals = np.array(GasMetals)\n",
    "    Gas = np.array(Gas)\n",
    "    Rad = np.array(Rad)\n",
    "    \n",
    "    return(Dust, GasMetals, Gas, Rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mass_and_metallicity_history(SAM_choice, directory, firstfile, lastfile, snap_limit):\n",
    "    '''\n",
    "    Build mass and metallicity history from the output directory of dusty-sage\n",
    "    Input:  - SAM_choice (int): (0) SAGE (1) Dusty-SAGE\n",
    "            - directory (string) -- path to the directory containing dusty-sage output tree\n",
    "            - snap_limit (integer) -- number of last snapshot\n",
    "            \n",
    "    Output: - Mass (array(list(float))) -- an array containing a number of galaxy, each containing mass (in Msun/h) of each snapshot\n",
    "            - Metallicity (array(list(float))) -- an array containing a number of galaxy, each containing stellar metallicity of each snapshot\n",
    "\n",
    "    '''\n",
    "    Mass = []\n",
    "    Metals = []\n",
    "\n",
    "    \n",
    "    for tree in iterate_trees(SAM_choice, directory, firstfile, lastfile):\n",
    "        mass, metals = calculate_mass_and_metals(SAM_choice, tree, snap_limit)\n",
    "        Mass.extend(mass)\n",
    "        Metals.extend(metals)\n",
    "\n",
    "    Mass = np.array(Mass)\n",
    "    Metals = np.array(Metals)\n",
    "    \n",
    "    return(Mass, Metals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filename):\n",
    "    \n",
    "    '''\n",
    "    Open file, read each line, split each line into each float number.\n",
    "    Create an list consists of all the number (float) in the file.\n",
    "    \n",
    "    Input: - filename (str) -- name of file to be opened\n",
    "    Output: - M (list(float)) -- a list of float consists of all number in the file named filename\n",
    "    '''\n",
    "    \n",
    "    f = open(filename, \"r\")\n",
    "    M = []\n",
    "    for elem in f.read().split():\n",
    "        try:\n",
    "            M.append(float(elem))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    f.close()\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_SED(SSP, Age, MassHist, MetalHist, tau_head_BC, tau_head_ISM, eta_BC, eta_ISM, time_BC):\n",
    "    \n",
    "    '''\n",
    "    Generate intrinsice (stellar) SED by assembling SSP from BC03.\n",
    "    \n",
    "    Input:  - Choice_of_SSP (int) : 0 - BC03\n",
    "            - Age : 1-dimension array consists of age of universe in Gyr\n",
    "            - MassHist: N-dimension array, with N=number of galaxy.\n",
    "                        Each array consists of stellar mass (in Msun) of each galaxy at corresponding age of Universe.\n",
    "            - MetalHist: N-dimension array, with N=number of galaxy.\n",
    "                         Each array consists of stellar metallicity (metals/stellar mass) of each galaxy at corresponding age of Universe.\n",
    "                         \n",
    "    Output: - Wavelength: 1-dimension array with 6900 wavelength in micrometer.\n",
    "            - Luminosity: N-dimension array, with N=number of galaxy.\n",
    "                          Each array consists of luminosity of galaxy at corresponding wavelength.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #SSP = 0 (Bruzual & Charlot 2003 -- BC03)\n",
    "    FileNames = [\"files/bc2003_hr_m22_chab_ssp.ised_ASCII\", \"files/bc2003_hr_m32_chab_ssp.ised_ASCII\",\n",
    "            \"files/bc2003_hr_m42_chab_ssp.ised_ASCII\", \"files/bc2003_hr_m52_chab_ssp.ised_ASCII\", \n",
    "            \"files/bc2003_hr_m62_chab_ssp.ised_ASCII\", \"files/bc2003_hr_m72_chab_ssp.ised_ASCII\"]\n",
    "\n",
    "    AllFiles = []\n",
    "    for i in range(len(FileNames)):\n",
    "        AllFiles.append(open_file(FileNames[i]))\n",
    "\n",
    "    File1 = AllFiles[0]\n",
    "    lookback = np.array(File1[1:222])\n",
    "    wavelength = np.array(File1[236: 7136])\n",
    "    metallicity = [0.0001, 0.0004, 0.004, 0.008, 0.02, 0.05] #metallicity grid in BC03\n",
    "    time_grid = 221\n",
    "    wave_grid = 6900\n",
    "    lookbacktime = age_to_lookback(Age)\n",
    "    sorted_lbtime = sorted(lookbacktime)\n",
    "\n",
    "    lum = np.zeros((len(AllFiles), time_grid, wave_grid))\n",
    "\n",
    "    for j in range(len(metallicity)):\n",
    "        File = AllFiles[j]\n",
    "        for i in range(time_grid):\n",
    "            lum[j][i] = File[7137 + (wave_grid+54)*i: 7137 + (wave_grid+54)*i + 6900]\n",
    "\n",
    "    #Check if all mass and metal history have the same number of timestep\n",
    "    if(len(MassHist) > 1):\n",
    "        for i in range(len(MassHist)):\n",
    "            if len(MassHist[i]) != len(MassHist[0]):\n",
    "                print(\"Not all galaxies have mass history at snapshot=\",i)\n",
    "            if len(MetalHist[i]) != len(MetalHist[0]):\n",
    "                print(\"Not all galaxies have metal history at snapshot=\", i)\n",
    "\n",
    "    w = np.where(lookback < 10**7)[0]\n",
    "\n",
    "    if(len(MassHist) > 1):\n",
    "        gal_number = len(MassHist)\n",
    "    else:\n",
    "        gal_number = 1\n",
    "\n",
    "    new_mass_hist = np.zeros((time_grid, gal_number))\n",
    "    new_metal_hist = np.zeros((time_grid, gal_number))\n",
    "\n",
    "    #   Build new mass and metal history based on the lookback time of BC03\n",
    "    for i in range(gal_number):\n",
    "\n",
    "        temp_mass_list = list(MassHist[i])\n",
    "        temp_metal_list = list(MetalHist[i])\n",
    "        temp_mass_list.reverse()\n",
    "        temp_metal_list.reverse()\n",
    "        new_mass_hist[:,i] = np.interp(lookback, sorted_lbtime, temp_mass_list) \n",
    "        new_metal_hist[:,i] = np.interp(lookback, sorted_lbtime, temp_metal_list) \n",
    "\n",
    "    #Count half metallicity of metallicity grids from BC03\n",
    "    half_metal = [0] * (len(metallicity) - 1)\n",
    "    for i in range(len(half_metal)):\n",
    "        half_metal[i] = (metallicity[i] + metallicity[i+1]) / 2\n",
    "\n",
    "    #print('Building SED')\n",
    "    total_lum = np.zeros((gal_number, wave_grid))\n",
    "    total_lum_dusty = np.zeros((gal_number, wave_grid))\n",
    "\n",
    "    tau_ISM = compute_tau(tau_head_ISM, eta_ISM, wavelength)\n",
    "    tau_BC = tau_ISM + compute_tau(tau_head_BC, eta_BC, wavelength)\n",
    "    \n",
    "    \n",
    "    attenuation_factor_BC = e**(-tau_BC)\n",
    "    attenuation_factor_ISM = e**(-tau_ISM)\n",
    "    \n",
    "    for i in range(len(lookback) - 1):\n",
    "        \n",
    "        if i%22 == 0:\n",
    "            print(int(i*100/219),'%',end = '')\n",
    "        else: \n",
    "            print('.',end = '')\n",
    "        \n",
    "        #print(\"Timestep\", i, \"/\", len(lookback) - 2)\n",
    "        delta_mass = new_mass_hist[i] - new_mass_hist[i+1]\n",
    "        deltamass = np.reshape(delta_mass, (-1, 1))\n",
    "\n",
    "        w1 = np.where(new_metal_hist[i] < half_metal[0])[0]\n",
    "        total_lum[w1] += deltamass[w1] * lum[0][i]\n",
    "\n",
    "        for j in range(len(half_metal)-1):\n",
    "            w2 = np.where((new_metal_hist[i] > half_metal[j]) & (new_metal_hist[i] <= half_metal[j+1]))[0]\n",
    "            total_lum[w2] += deltamass[w2] * lum[j+1][i]\n",
    "\n",
    "        w3 = np.where(new_metal_hist[i] > half_metal[-1])[0]\n",
    "        total_lum[w3] += deltamass[w3] * lum[-1][i]\n",
    "\n",
    "\n",
    "        #birthcloud extinction\n",
    "        if (lookback[i] < time_BC):\n",
    "            total_lum_dusty = total_lum * attenuation_factor_BC\n",
    "        else:\n",
    "            total_lum_dusty = total_lum * attenuation_factor_ISM\n",
    "        \n",
    "    return wavelength, total_lum, total_lum_dusty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau(tau_head, eta, wavelength):\n",
    "    \n",
    "    '''\n",
    "    Compute optical depth as a function of wavelength using Charlot and Fall (2000) model\n",
    "    \n",
    "    Input:  - tau_head (float or array): optical depth at 5500 Angstorm\n",
    "            - eta (float or array): power law index\n",
    "            - wavelength (array): in Angstorn           \n",
    "    Output: - tau (array): the computed optical depth have the same dimension with wavelength. \n",
    "    '''\n",
    "\n",
    "    \n",
    "    if type(tau_head) != float:\n",
    "        tau = np.zeros((len(tau_head), len(wavelength)))\n",
    "        for i in range(len(tau)):\n",
    "            tau[i] = tau_head[i] * (wavelength/5500)**eta[i]\n",
    "    else:\n",
    "        tau = tau_head * (wavelength/5500)**eta\n",
    "\n",
    "    return(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area(rad):\n",
    "    '''\n",
    "    Compute area of a disk (2 * area of a circle)\n",
    "    \n",
    "    Input:  - rad (float or array): radius\n",
    "    Output: - area (float or array): area of a disk for given radius\n",
    "    '''\n",
    "\n",
    "    return (2 * np.pi * rad**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tauBC_Trayford(ColdDust, ColdGas, rad):\n",
    "    '''\n",
    "    Compute optical depth at 5500 A for birth clouds using relation in Trayford+ 19\n",
    "    (relation between dust surface density and optical depth)\n",
    "    \n",
    "    Input:  - ColdDust (float or array): total cold dust mass in the ISM in Msun\n",
    "            - ColdGas (float or array): total cold gas mass in the ISM in Msun\n",
    "            - rad (float or array): disk radius in Mpc\n",
    "    Output: - Sigma_BC (float or array): dust surface density in the birth clouds (logscale Msun/kpc2)\n",
    "            - tau_BC (float or array): optical depth at 5500 A for birth clouds\n",
    "    '''\n",
    "    \n",
    "    fdust = ColdDust / ColdGas\n",
    "    ScaleRad = rad * 1e6 #convert to pc\n",
    "    halfrad = 1.68 * ScaleRad \n",
    "    threerad = 0.4 * ScaleRad\n",
    "    \n",
    "    fdust_MW = 0.33\n",
    "    Zsun = 0.0189\n",
    "    Sigma_MW = 85 #Msun/pc2 \n",
    "    \n",
    "    #area = compute_area(halfrad)\n",
    "    area = compute_area(threerad)\n",
    "    Sigma_gas = ColdGas / area\n",
    "    w = np.where(Sigma_gas < Sigma_MW)[0]\n",
    "    if len(w) > 1:\n",
    "        Sigma_gas[w] = Sigma_MW\n",
    "    elif len(w) == 1:\n",
    "        Sigma_gas = Sigma_MW\n",
    "    tau_BC = (fdust * Sigma_gas) / (fdust_MW * Zsun * Sigma_MW)\n",
    "    Sigma_BC = np.log10(fdust * Sigma_gas * 1e6) #kpc\n",
    "    \n",
    "    return Sigma_BC, tau_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tauISM_Trayford(ColdDust, ColdGas, rad):\n",
    "    '''\n",
    "    Compute ISM optical depth from relation in Trayford+ 19\n",
    "    \n",
    "    Input:  - ColdDust (float or array): total cold dust mass in the ISM (Msun)\n",
    "            - ColdGas (float or array): total cold gas mass in the ISM (Msun)\n",
    "            - rad (float or array): disk radius in Mpc\n",
    "    Output: - Sigma_dust (float or array): dust surface density in the diffuse ISM (in logscale - Msun/kpc2)\n",
    "            - tau_ISM (float or array): optical depth at 5500 A for diffuse ISM\n",
    "    '''\n",
    "    ScaleRad = rad * 1e3 #convert to kpc\n",
    "    halfrad = 1.68 * ScaleRad\n",
    "    threerad = 0.4 * ScaleRad\n",
    "    Sigma_MW = 85 * 1e6 #Msun/kpc2\n",
    "    \n",
    "    Sigma_dust_Trayford = [4.088, 4.351, 4.579, 4.823, 5.057, 5.292, 5.528, 5.765, 6.001, 6.234, 6.470, 6.704, 6.941, 7.177, 7.416]\n",
    "    tau_head_Trayford = [0.031, 0.059, 0.078, 0.129, 0.203, 0.308, 0.467, 0.647, 0.838, 1.065, 1.235, 1.475, 1.571, 1.645, 1.806]\n",
    "\n",
    "    #area = compute_area(halfrad)\n",
    "    area = compute_area(threerad)\n",
    "        \n",
    "    Sigma_dust = np.log10(ColdDust / area)\n",
    "    #Sigma_dust = np.log10(fdust * Sigma_gas)\n",
    "    tau_ISM = np.interp(Sigma_dust, Sigma_dust_Trayford, tau_head_Trayford)\n",
    "    \n",
    "    return Sigma_dust, tau_ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_etaISM_Trayford(ColdDust, ColdGas, rad):\n",
    "    '''\n",
    "    Compute powerlaw index for the diffuse ISM component from relation in Trayford+ 19\n",
    "    \n",
    "    Input:  - ColdDust (float or array): total cold dust mass in the ISM in Msun\n",
    "            - ColdGas (float or array): total cold gas mass in the ISM in Msun\n",
    "            - rad (float or array): disk radius in Mpc\n",
    "    Output: - Sigma_dust (float or array): dust surface density in the diffuse ISM (logscale Msun/kpc2)\n",
    "            - eta_ISM (float or array): powerlaw index for diffuse ISM\n",
    "    '''\n",
    "\n",
    "    ScaleRad = rad * 1e3 #convert to kpc\n",
    "    halfrad = 1.68 * ScaleRad\n",
    "    threerad = 0.4 * ScaleRad\n",
    "    \n",
    "    Sigma_dust_Trayford = [4.116, 4.354, 4.588, 4.822, 5.061, 5.293, 5.533, 5.763, 6.003, 6.236, 6.469, 6.706, 6.943, 7.181, 7.411]\n",
    "    eta_ISM_Trayford = [-1.379, -1.357, -1.334, -1.243, -1.170, -1.062, -0.922, -0.778, -0.668, -0.570, -0.506, -0.453, -0.381, -0.318, -0.307]\n",
    "    #area = compute_area(halfrad)\n",
    "    area = compute_area(threerad)\n",
    "    \n",
    "    Sigma_dust = np.log10(ColdDust / area)\n",
    "    #Sigma_dust = np.log10(fdust * Sigma_gas)\n",
    "    eta_ISM = np.interp(Sigma_dust, Sigma_dust_Trayford, eta_ISM_Trayford)\n",
    "    \n",
    "    return Sigma_dust, eta_ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tauISM_Somerville (Dust, Rad):\n",
    "    '''\n",
    "    Compute ISM optical depth from prescription in Somerville+ 2012\n",
    "    \n",
    "    Input:  - ColdDust (float or array): total cold dust mass in the ISM in Msun\n",
    "            - rad (float or array): disk radius in Mpc\n",
    "    Output: - Sigma_dust (float or array): dust surface density in the diffuse ISM (Msun/pc2)\n",
    "            - tau_ISM (float or array): optical depth at 5500 A for diffuse ISM\n",
    "    '''\n",
    "    \n",
    "    Chi_gas = 0.42\n",
    "    rad_gas = Chi_gas * Rad * 1e6\n",
    "    \n",
    "    tau_dust_0 = 0.3\n",
    "    Sigma = Dust / (rad_gas**2) \n",
    "    tau_ISM = tau_dust_0 * Sigma\n",
    "    \n",
    "    return(Sigma, tau_ISM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tauBC_Somerville (Dust, Rad):\n",
    "    \n",
    "    '''\n",
    "    Compute birth clouds' optical depth from prescription in Somerville+ 2012\n",
    "    \n",
    "    Input:  - ColdDust (float or array): total cold dust mass in the ISM in Msun\n",
    "            - rad (float or array): disk radius in Mpc\n",
    "    Output: - Sigma_dust (float or array): dust surface density in the Birth Clouds (Msun/pc2)\n",
    "            - tau_ISM (float or array): optical depth at 5500 A for Birth Clouds\n",
    "    '''\n",
    "    \n",
    "    Chi_gas = 0.42\n",
    "    rad_gas = Chi_gas * Rad * 1e6\n",
    "    \n",
    "    tau_dust_0 = 0.3\n",
    "    Sigma = Dust / (rad_gas**2)\n",
    "    tau_ISM = tau_dust_0 * Sigma\n",
    "    \n",
    "    mu_BC = 6\n",
    "    tau_BC = mu_BC * tau_ISM\n",
    "    \n",
    "    return (Sigma, tau_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attenuation_parameters (prescription_choice, DustMass, GasMass, Radius):\n",
    "    '''\n",
    "    Compute attenuation parameters based on the Charlot & Fall (2000) model.\n",
    "    We adopted two prescriptions to compute the parameters:\n",
    "    Input:  - prescription_choice (int): (0) Lagos+ 19 (1) Somerville+ 12\n",
    "            - DustMass (float or array): Dust mass in Msun\n",
    "            - GasMass (float or array): Gas mass in Msun\n",
    "            \n",
    "    Output: - Mass (array(list(float))) -- an array containing a number of galaxy, each containing mass (in Msun/h) of each snapshot\n",
    "            - Metallicity (array(list(float))) -- an array containing a number of galaxy, each containing stellar metallicity of each snapshot\n",
    "\n",
    "    '''\n",
    "\n",
    "    eta_BC = [-0.7] * len(DustMass)\n",
    "    eta_ISM = np.zeros(len(DustMass))\n",
    "    tau_BC = np.zeros(len(DustMass))\n",
    "    tau_ISM = np.zeros(len(DustMass))  \n",
    "    \n",
    "    w = np.where(DustMass > 0)[0]\n",
    "    \n",
    "    if prescription_choice == 0:\n",
    "        Sigma_BC, tau_BC[w] = compute_tauBC_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "        Sigma_tau_ISM, tau_ISM[w] = compute_tauISM_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "        Sigma_eta_ISM, eta_ISM[w] = compute_etaISM_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "\n",
    "    elif prescription_choice == 1:\n",
    "        eta_ISM[w] = -1.3\n",
    "        Sigma_ISM, tau_ISM[w] = compute_tauISM_Somerville (DustMass[w], Radius[w])\n",
    "        Sigma_BC, tau_BC[w] = compute_tauBC_Somerville (DustMass[w], Radius[w])\n",
    "    \n",
    "    else:\n",
    "        print(\"Choose 0 for attenuation prescriptions from Lagos+19 and 1 for Somerville+12\")\n",
    "        \n",
    "    return tau_BC, eta_BC, tau_ISM, eta_ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_idx_Rieke(LIR):\n",
    "    \n",
    "    '''\n",
    "    Determine the index of the Dale+ 14 IR template to be used based on the total IR luminosity\n",
    "    from the prescription in Rieke+ 09\n",
    "    \n",
    "    Input:  - LIR (float or array): total IR luminosity in Lsun\n",
    "    Output: - idx (float or array): index of the spectra in the Dale+ 14 IR template\n",
    "    '''\n",
    "\n",
    "    alpha_SF, log_fnu_SF = np.loadtxt('files/alpha.dat', unpack=True)\n",
    "    \n",
    "    if (LIR > 10**11.6):  \n",
    "        LIR = 10**11.6\n",
    "\n",
    "    alpha = 10.096 - 0.741 * np.log10(LIR)\n",
    "\n",
    "    delta_alpha = abs(alpha_SF - alpha)\n",
    "    idx = np.where(delta_alpha==min(delta_alpha))[0]    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_idx_Marcillac(LIR):\n",
    "    '''\n",
    "    Determine the index of the Dale+ 14 IR template to be used based on the total IR luminosity\n",
    "    from the prescription in Marcillac+ 06\n",
    "    \n",
    "    Input:  - LIR (float or array): total IR luminosity in Lsun\n",
    "    Output: - idx (float or array): index of the spectra in the Dale+ 14 IR template\n",
    "    '''\n",
    "\n",
    "    alpha_SF, log_fnu_SF = np.loadtxt('files/alpha.dat', unpack=True)\n",
    "    log_fnu = 0.128 * np.log10(LIR) - 1.611\n",
    "    delta_fnu = abs(log_fnu_SF - log_fnu)\n",
    "    idx = np.where(delta_fnu==min(delta_fnu))[0]    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_IR_Dale (wavelength, spectra, spectra_dusty):\n",
    "\n",
    "    '''\n",
    "    Add the NIR-FIR spectra from Dale+ 14 IR template to the UV-NIR spectra from BC03/\n",
    "    \n",
    "    Input:  - wavelength (N-dimensional array)\n",
    "            - spectra (N-dimensional array) - intrinsic stellar spectra corresponding to each wavelength\n",
    "            - spectra_dusty (N-dimensional array) - attenuated spectra corresponding to each wavelength\n",
    "    Output: - wavelength (M-dimensional array) - M > N\n",
    "            - spectra (M-dimensional array) - attenuated spectra with IR addition\n",
    "    '''\n",
    "    \n",
    "    Dale_template = np.loadtxt('files/spectra.0.00AGN.dat', unpack=True)\n",
    "    lambda_IR = Dale_template[0] * 1e4 #convert from micron to Angstrom\n",
    "\n",
    "    Ldust = (spectra - spectra_dusty)\n",
    "    w = np.where(wavelength < 912)[0]\n",
    "    idx_912 = w[-1]\n",
    "\n",
    "    all_wave = np.unique(np.concatenate((wavelength, lambda_IR)))\n",
    "    all_wave.sort(kind='mergesort')\n",
    "    UVIR = np.zeros((len(Ldust), len(all_wave)))\n",
    "    \n",
    "    for i in range(len(Ldust)):\n",
    "        LIR_mentari = trapz(Ldust[i][idx_912:-1], wavelength[idx_912:-1])\n",
    "        #---------------------------------------------------\n",
    "        '''\n",
    "        #Compute alpha based on Rieke+ 2009\n",
    "        if (LIR_mentari > 10**11.6):  \n",
    "            LIR_mentari = 10**11.6\n",
    "\n",
    "        alpha = 10.096 - 0.741 * np.log10(LIR_mentari)\n",
    "\n",
    "        delta_alpha = abs(alpha_SF - alpha)\n",
    "        idx = np.where(delta_alpha==min(delta_alpha))[0]\n",
    "\n",
    "        #----------------------------------------------------\n",
    "        #Compute log_fnu based on Marcillac+ 2006\n",
    "        log_fnu = 0.128 * np.log10(LIR_mentari) - 1.611\n",
    "        delta_fnu = abs(log_fnu_SF - log_fnu)\n",
    "        idx = np.where(delta_fnu==min(delta_fnu))[0]\n",
    "        #----------------------------------------------------\n",
    "        '''\n",
    "        idx = determine_idx_Marcillac(LIR_mentari)\n",
    "        spectra_IR = 10 ** Dale_template[idx[0]+1] \n",
    "\n",
    "        LIR_dale = trapz(spectra_IR, lambda_IR)\n",
    "        scaling = LIR_mentari / LIR_dale\n",
    "        spectra_IR_dale = spectra_IR * scaling \n",
    "\n",
    "        wa = np.where((all_wave < wavelength[-1]) | (all_wave == wavelength[-1]))[0]\n",
    "        UVIR[i][wa] += np.interp(all_wave[wa], wavelength, spectra_dusty[i])\n",
    "\n",
    "        we = np.where((all_wave > lambda_IR[0]) | (all_wave == lambda_IR[0]))[0]\n",
    "        UVIR[i][we] += np.interp(all_wave[we], lambda_IR, spectra_IR_dale)\n",
    "\n",
    "    return (all_wave, UVIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contains some simple functions for working with the Safarzadeh et al. (2015)\n",
    "FIR SED templates.\n",
    "\n",
    "The find_template function returns the SED template that\n",
    "is the best match for the log (L_IR/L_sun) and log (M_dust/M_sun) values\n",
    "specified by the user.\n",
    "\n",
    "The load_templates function reads the ASCII file that\n",
    "contains the template data and returns arrays that contain the L_IR and M_dust\n",
    "values for each template, a 2-D array that contains the normalized SEDs\n",
    "(lambda*L_lambda/L_IR), and the wavelength array.\n",
    "\n",
    "\"\"\"\n",
    "def find_template_SUNRISE(\n",
    "    lir, #\"\"\"logarithm of the IR luminosity in solar units\"\"\"\n",
    "    mdust, #\"\"\"logarithm of the dust mass in solar units\"\"\"\n",
    "    tol=0.5, #\"\"\"maximum allowed discrepancy between template and requested values, delta(L_IR, M_dust); see function docstring\"\"\"\n",
    "    #rtol=0.2, #\"\"\"maximum allowed difference between the template and requested L_IR/M_dust ratio\"\"\"\n",
    "    rtol=0.5,\n",
    "    sed_file=\"safarzadeh_et_al_2015.txt\", #\"\"\"full path to file that contains the templates\"\"\"\n",
    "    verbose=True #\"\"\"prints messages if set to True\"\"\"\n",
    "    ):\n",
    "    \"\"\"Return template with (L_IR, M_dust) values closest to those requested.\n",
    "\n",
    "    Similarity is defined by the Euclidean distance between the requested and template \n",
    "    (L_IR, M_dust) values,\n",
    "\n",
    "        delta(L_IR, M_dust) = [(L_IR,requested - L_IR, template)^2\n",
    "            + (M_dust,requested - M_dust,template)^2]^(0.5)\n",
    "\n",
    "    If no template with delta(L_IR, M_dust) < tol is found, then search for a template with an\n",
    "    L_IR/M_dust ratio that differs from that requested by at most rtol.\n",
    "\n",
    "    Parameters:\n",
    "        - lir : log (L_IR/L_sun) value for which a template is desired\n",
    "        - mdust : log (M_dust/M_sun) value for which a template is desired\n",
    "        - tol : maximum allowed delta(L_IR, M_dust) value\n",
    "        - rtol : maximum allowed difference between requested and template L_IR/M_dust ratio;\n",
    "        only used if delta(L_IR, M_dust) < tol cannot be satisfied\n",
    "        - sed_file : full path to file that contains the template\n",
    "        - verbose : print helpful messages if set to True\n",
    "\n",
    "    Returns:\n",
    "        - lambda_array: array of wavelengths (in micron)\n",
    "        - sed: template SED that is most appropriate for the (L_IR, M_dust) requested; the\n",
    "            template is normalized such that its total IR luminosity equals  the *requested*\n",
    "            L_IR value (i.e. the normalized SED from the template file is multipled by L_IR\n",
    "\n",
    "    Example:\n",
    "        Find an SED for a galaxy with L_IR = 10^11 L_sun and M_dust = 10^8 M_sun:\n",
    "\n",
    "            lam, sed = find_template(11.,8.)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    lir_array, mdust_array, sed_array, lambda_array = load_templates_SUNRISE()\n",
    "\n",
    "    dist = ((lir_array - lir)**2 + (mdust_array - mdust)**2)**(0.5)\n",
    "    \n",
    "    # first try to find a template with delta(L_IR,M_dust) < tol (see function docstring)\n",
    "    if dist.min() < tol :\n",
    "        '''\n",
    "        if verbose :\n",
    "            print (\"Template sufficiently close in the (L_IR, M_dust) plane found\")\n",
    "            print (\"Requested: log L_IR = \", lir, \", log M_dust = \", mdust)\n",
    "            print (\"Template: log L_IR = \", lir_array[dist.argmin()], \", log M_dust = \", \\\n",
    "                mdust_array[dist.argmin()])\n",
    "        '''\n",
    "        return lambda_array, sed_array[dist.argmin(),:]*10.**lir\n",
    "    else : # not found, so search for one with delta(L_IR/M_dust) < rtol (see function docstring)\n",
    "        '''\n",
    "        if verbose :\n",
    "            print (\"Template with delta(L_IR, M_dust) < \",tol,\" not found. Returning template with nearest L_IR/M_dust value instead\")\n",
    "        '''\n",
    "        ratio=lir-mdust\n",
    "        ratio_array=lir_array-mdust_array\n",
    "        dist_ratio = np.abs(ratio - ratio_array)\n",
    "        if dist_ratio.min() < rtol :\n",
    "            '''\n",
    "            if verbose :\n",
    "                print (\"Found template with sufficiently similar L_IR/M_dust ratio\")\n",
    "                print (\"Requested: log L_IR = \", lir, \", log M_dust = \", mdust, \\\n",
    "                    \", log L_IR/M_dust = \",ratio)\n",
    "                print (\"Template: log L_IR = \", lir_array[dist_ratio.argmin()], \", log M_dust = \", \\\n",
    "                    mdust_array[dist_ratio.argmin()],\", log L_IR/M_dust = \", \\\n",
    "                    ratio_array[dist_ratio.argmin()])\n",
    "            '''\n",
    "            sed = sed_array[dist_ratio.argmin(),:]*10.**lir\n",
    "            return lambda_array, sed\n",
    "        else : # didn't find a suitable template\n",
    "            #print (\"ERROR: acceptable template not found, mdust = \" + str(mdust) + \"mdust = \")\n",
    "            return lambda_array, np.zeros(len(lambda_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates_SUNRISE(\n",
    "    sed_file = \"safarzadeh_et_al_2015.txt\" #\"\"\"full path to file that contains the templates\"\"\"\n",
    "    ):\n",
    "    \"\"\"Read the ASCII file that contains the template data.\n",
    "\n",
    "    Parameters:\n",
    "        - sed_file: the full path to the template file.\n",
    "\n",
    "    Returns:\n",
    "        - lir_array : log (L_IR/L_sun) for each template\n",
    "\n",
    "        - mdust_array : log (M_dust/M_sun) for each template\n",
    "\n",
    "        - sed_array: the actual SEDs (lambda*L_lambda) normalized by dividing by L_IR.\n",
    "        The first dimension is the template number, and the second is wavelength.\n",
    "    \n",
    "        - lambda_array: the wavelengths (in microns) at which the SEDs are provided\n",
    "\n",
    "    Example:\n",
    "        import template_functions as tf\n",
    "        lir_array, mdust_array, sed_array, lambda_array = tf.load_templates()\n",
    "    \"\"\"\n",
    "\n",
    "    lir_array = np.loadtxt(sed_file,skiprows=21,usecols=[0])\n",
    "    mdust_array = np.loadtxt(sed_file,skiprows=21,usecols=[1])\n",
    "    sed_array = np.loadtxt(sed_file,skiprows=21,usecols=(np.arange(19)+3))\n",
    "    lambda_array = np.loadtxt(sed_file,skiprows=20,usecols=(np.arange(19)+3))[0,:]*1.e6\n",
    "\n",
    "    return lir_array, mdust_array, sed_array, lambda_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IR_SUNRISE (Dust, wavelength, spectra, spectra_dusty):\n",
    "    \n",
    "    '''\n",
    "    Compute the FIR spectra from SUNRISE model Safarzadeh+ 15    \n",
    "    Input:  - Dust (array): dust mass in Msun/h\n",
    "            - wavelength (array): in UV-NIR\n",
    "            - spectra (array): intrinsic spectra corresponding to each wavelength\n",
    "            - spectra_dusty (array): attenuated spectra corresponding to each wavelength\n",
    "    Output: - wave_IR (array): wavelength in FIR\n",
    "            - lum_IR (array): IR spectra at each corresponding FIR wavelength\n",
    "    '''\n",
    "    w = np.where(Dust > 5e5)[0]\n",
    "    if len(w) > 0:\n",
    "        new_dust = Dust[w]\n",
    "        Ldust = (spectra[w] - spectra_dusty[w])\n",
    "        w = np.where(wavelength < 912)[0]\n",
    "        idx_912 = w[-1]\n",
    "\n",
    "        LIR_mentari = np.trapz(Ldust[0][idx_912:-1], wavelength[idx_912:-1])\n",
    "        lam, sed  = find_template_SUNRISE(np.log10(LIR_mentari), np.log10(new_dust[0]))\n",
    "        wave_IR = lam * 1e4\n",
    "        lum_IR = np.zeros((len(Ldust), len(wave_IR)))\n",
    "\n",
    "        for i in range(len(Ldust)):\n",
    "            LIR_mentari = np.trapz(Ldust[i][idx_912:-1], wavelength[idx_912:-1])\n",
    "            lam, sed = find_template_SUNRISE(np.log10(LIR_mentari), np.log10(new_dust[i]))\n",
    "            lum_IR[i] = sed / (lam * 1e4)   \n",
    "\n",
    "    else:\n",
    "\t\n",
    "        wave_IR = 0\n",
    "        lum_IR = 0\n",
    "    return (wave_IR, lum_IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_Dale_SUNRISE(DustMass, wavelength, spectra, spectra_dusty):\n",
    "    '''\n",
    "    Compute the FIR spectra from SUNRISE model Safarzadeh+ 15 and combine it with FUV - NIR BC03 spectra and MIR Dale+ 14 spectra \n",
    "    Input:  - Dust (array): dust mass in Msun/h\n",
    "            - wavelength (array): in UV-MIR\n",
    "            - spectra (array): intrinsic spectra corresponding to each wavelength\n",
    "            - spectra_dusty (array): attenuated spectra corresponding to each wavelength\n",
    "    Output: - wave_IR (array): wavelength in UV - FIR\n",
    "            - lum_IR (array): IR spectra at each corresponding wavelength\n",
    "    '''\n",
    "    lir_array, mdust_array, sed_array, lambda_array = load_templates_SUNRISE()\n",
    "    wavelength_dale, spectra_dale = add_IR_Dale(wavelength, spectra, spectra_dusty)\n",
    "    wavelength_sunrise = lambda_array * 1e4 #convert micrometer to angstrom\n",
    "\n",
    "    w = np.where(wavelength_dale < wavelength_sunrise[0])\n",
    "    all_wave = np.unique(np.concatenate((wavelength_dale[w], wavelength_sunrise)))\n",
    "    all_wave.sort(kind='mergesort')\n",
    "    new_spec = np.zeros((len(DustMass), len(all_wave)))\n",
    "    \n",
    "    Ldust = (spectra - spectra_dusty)\n",
    "    w = np.where(wavelength < 912)[0]\n",
    "    idx_912 = w[-1]\n",
    "\n",
    "    for i in range(len(Ldust)):\n",
    "        LIR_mentari = trapz(Ldust[i][idx_912:-1], wavelength[idx_912:-1])\n",
    "        if DustMass[i] > 0:\n",
    "            lam, sed = find_template_SUNRISE(np.log10(LIR_mentari), np.log10(DustMass[i]))\n",
    "        else:\n",
    "            lam, sed = find_template_SUNRISE(0, 0)\n",
    "        spectra_sunrise = sed / (lam * 1e4)   \n",
    "\n",
    "        wa = np.where((all_wave < wavelength_sunrise[0]) | (all_wave == wavelength_sunrise[0]))[0]\n",
    "        new_spec[i][wa] += np.interp(all_wave[wa], wavelength_dale, spectra_dale[i])\n",
    "\n",
    "        wb = np.where(all_wave > wavelength_sunrise[0])[0]\n",
    "        new_spec[i][wb] += np.interp(all_wave[wb], wavelength_sunrise, spectra_sunrise)\n",
    "                \n",
    "    return all_wave, new_spec\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_Dale_SUNRISE(wavelength_sunrise, spectra_sunrise, wavelength_dale, spectra_dale):\n",
    "    '''\n",
    "    Combine UV-MIR spectra from BC03 and Dale+ 14 with the FIR spectra from SUNRISE (Safarzadeh+15)    \n",
    "    Input:  - wavelength_sunrise (array): in FIR\n",
    "            - spectra_sunrise (array): FIR spectra from Safarzadeh+14\n",
    "            - wavelength_dale (array): in UV-NIR\n",
    "            - spectra_dale (array): combination of BC03 and Dale+14 spectra in UV-NIR\n",
    "    Output: - all_wave (array): wavelength in UV-IR\n",
    "            - new_spec (array): combination of BC03 (UV-NIR), Dale+14 (MIR), and Safarzadeh+ 15 (FIR)\n",
    "    '''\n",
    "\n",
    "    w = np.where(wavelength_dale < wavelength_sunrise[0])\n",
    "    all_wave = np.unique(np.concatenate((wavelength_dale[w], wavelength_sunrise)))\n",
    "    all_wave.sort(kind='mergesort')\n",
    "    \n",
    "    new_spec = np.zeros((len(spectra_sunrise), len(all_wave)))\n",
    "    for i in range(len(spectra_sunrise)):\n",
    "        w = np.where((all_wave < wavelength_sunrise[0]) | (all_wave == wavelength_sunrise[0]))[0]\n",
    "        UVIR = np.interp(all_wave[w], wavelength_dale, spectra_dale[i])\n",
    "        new_spec[i][w] = UVIR\n",
    "        w = np.where(all_wave > wavelength_sunrise[0])[0]\n",
    "        new_spec[i,w] = np.interp(all_wave[w], wavelength_sunrise, spectra_sunrise[i])\n",
    "\n",
    "    return (all_wave, new_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_lookback(age): #age in Gyr, lookback in yr\n",
    "    \n",
    "    '''\n",
    "    Convert age of Universe to lookback time\n",
    "    Input: age (list(float)) -- age of universe, in Gyr\n",
    "    Output: lookback time (list(float)) -- corresponding lookback time, in yr\n",
    "    '''\n",
    "    lookback = (np.array([13.6098]*len(age)) - age) * 1.e9\n",
    "    return lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filters():\n",
    "    \n",
    "    '''\n",
    "    Reading filters wavelength and response listed in 'files/allfilters.dat'\n",
    "    '''\n",
    "    \n",
    "    F = type('', (), {})\n",
    "    F.wavelength, F.response = np.loadtxt('files/allfilters.dat', unpack=True)\n",
    "    F.Johnson_V_wave = F.wavelength[0:24]\n",
    "    F.Johnson_V = F.response[0:24]\n",
    "    F.Johnson_U_wave = F.wavelength[24:49]\n",
    "    F.Johnson_U = F.response[24:49]\n",
    "    F.Johnson_B_wave = F.wavelength[49:70]\n",
    "    F.Johnson_B = F.response[49:70]\n",
    "    F.Buser_B2_wave = F.wavelength[70:110]\n",
    "    F.Buser_B2 = F.response[70:110]\n",
    "    F.Cousins_R_wave = F.wavelength[110:175]\n",
    "    F.Cousins_R = F.response[110:175]\n",
    "    F.Cousins_I_wave = F.wavelength[175:214]\n",
    "    F.Cousins_I = F.response[175:214]\n",
    "    F.Deep_B_wave = F.wavelength[214:584]\n",
    "    F.Deep_B = F.response[214:584]\n",
    "    F.Deep_R_wave = F.wavelength[584:750]\n",
    "    F.Deep_R = F.response[584:750]\n",
    "    F.Deep_I_wave = F.wavelength[750:1106]\n",
    "    F.Deep_I = F.response[750:1106]\n",
    "    F.TwoMass_J_wave = F.wavelength[1106:1214]\n",
    "    F.TwoMass_J = F.response[1106:1214]\n",
    "    F.TwoMass_H_wave = F.wavelength[1214:1272]\n",
    "    F.TwoMass_H = F.response[1214:1272]\n",
    "    F.TwoMass_Ks_wave = F.wavelength[1272:1347]\n",
    "    F.TwoMass_Ks = F.response[1272:1347]\n",
    "    F.Sdss_u_wave = F.wavelength[1347:1394]\n",
    "    F.Sdss_u = F.response[1347:1394]\n",
    "    F.Sdss_g_wave = F.wavelength[1394:1483]\n",
    "    F.Sdss_g = F.response[1394:1483]\n",
    "    F.Sdss_r_wave = F.wavelength[1483:1558]\n",
    "    F.Sdss_r = F.response[1483:1558]\n",
    "    F.Sdss_i_wave = F.wavelength[1558:1647]\n",
    "    F.Sdss_i = F.response[1558:1647]\n",
    "    F.Sdss_z_wave = F.wavelength[1647:1788]\n",
    "    F.Sdss_z = F.response[1647:1788]\n",
    "    F.WFPC2_F255W_wave = F.wavelength[1788:11788]\n",
    "    F.WFPC2_F255W = F.response[1788:11788]\n",
    "    F.WPC2_F300W_wave = F.wavelength[11788:21788]\n",
    "    F.WFPC2_F300W = F.response[11788:21788]\n",
    "    F.WFPC2_F336W_wave = F.wavelength[21788:31788]\n",
    "    F.WFPC2_F336W = F.response[21788:31788]\n",
    "    F.WFPC2_F439W_wave = F.wavelength[31788:41788]\n",
    "    F.WFPC2_F439W = F.response[31788:41788]\n",
    "    F.WFPC2_F450W_wave = F.wavelength[41788:51788]\n",
    "    F.WFPC2_F450W = F.response[41788:51788]\n",
    "    F.WFPC2_F555W_wave = F.wavelength[51788:61788]\n",
    "    F.WFPC2_F555W = F.response[51788:61788]\t\n",
    "    F.WFPC2_F606W_wave = F.wavelength[61788:71788]\n",
    "    F.WFPC2_F606W = F.response[61788:71788]\n",
    "    F.WFPC2_F814W_wave = F.wavelength[71788:81788]\n",
    "    F.WFPC2_F814W = F.response[71788:81788]\n",
    "    F.WFPC2_F850W_wave = F.wavelength[81788:91788]\n",
    "    F.WFPC2_F850W = F.response[81788:91788]\n",
    "    F.WFCACS_F435W_wave = F.wavelength[91788:101788]\n",
    "    F.WFCACS_F435W = F.response[91788:101788]\n",
    "    F.WFCACS_F475W_wave = F.wavelength[101788:111788]\n",
    "    F.WFCACS_F475W = F.response[101788:111788]\n",
    "    F.WFCACS_F555W_wave = F.wavelength[111788:121788]\n",
    "    F.WFCACS_F555W = F.response[111788:121788]\n",
    "    F.WFCACS_F606W_wave = F.wavelength[121788:131788]\n",
    "    F.WFCACS_F606W = F.response[121788:131788]\n",
    "    F.WFCACS_F625W_wave = F.wavelength[131788:141788]\n",
    "    F.WFCACS_F625W = F.response[131788:141788]\n",
    "    F.WFCACS_F775W_wave = F.wavelength[141788:151788]\n",
    "    F.WFCACS_F775W = F.response[141788:151788]\n",
    "    F.WFCACS_F814W_wave = F.wavelength[151788:161788]\n",
    "    F.WFCACS_F814W = F.response[151788:161788]\n",
    "    F.WFCACS_F850W_wave = F.wavelength[161788:171788]\n",
    "    F.WFCACS_F850W = F.response[161788:171788]\n",
    "    F.WFC3UVIS_F218W_wave = F.wavelength[171788:180742]\n",
    "    F.WFC3UVIS_F218W = F.response[171788:180742]\n",
    "    F.WFC3UVIS_F225W_wave = F.wavelength[180742:189757]\n",
    "    F.WFC3UVIS_F225W = F.response[180742:189757]\n",
    "    F.WFC3UVIS_F275W_wave = F.wavelength[189757:198762]\n",
    "    F.WFC3UVIS_F275W = F.response[189757:198762]\n",
    "    F.WFC3UVIS_F336W_wave = F.wavelength[198762:207777]\n",
    "    F.WFC3UVIS_F336W = F.response[198762:207777]\n",
    "    F.WFC3UVIS_F390W_wave = F.wavelength[207777:216792]\n",
    "    F.WFC3UVIS_F390W = F.response[207777:216792]\t\n",
    "    F.WFC3UVIS_F438W_wave = F.wavelength[216792:225807]\n",
    "    F.WFC3UVIS_F438W = F.response[216792:225807]\n",
    "    F.WFC3UVIS_F475W_wave = F.wavelength[225807:234822]\n",
    "    F.WFC3UVIS_F475W = F.response[225807:234822]\n",
    "    F.WFC3UVIS_F555W_wave = F.wavelength[234822:243837]\n",
    "    F.WFC3UVIS_F555W = F.response[234822:243837]\t\n",
    "    F.WFC3UVIS_F606W_wave = F.wavelength[243837:252792]\n",
    "    F.WFC3UVIS_F606W = F.response[243837:252792]\n",
    "    F.WFC3UVIS_F775W_wave = F.wavelength[252792:261807]\n",
    "    F.WFC3UVIS_F775W = F.response[252792:261807]\n",
    "    F.WFC3UVIS_F814W_wave = F.wavelength[261807:270822]\n",
    "    F.WFC3UVIS_F814W = F.response[261807:270822]\t\n",
    "    F.WFC3UVIS_F850W_wave = F.wavelength[270822:279837]\n",
    "    F.WFC3UVIS_F850W = F.response[270822:279837]\n",
    "    F.WFC3IR_F098M_wave = F.wavelength[279837:284338]\n",
    "    F.WFC3IR_F098M = F.response[279837:284338]\n",
    "    F.WFC3IR_F105W_wave = F.wavelength[284338:293339]\n",
    "    F.WFC3IR_F105W = F.response[284338:293339]\n",
    "    F.WFC3IR_F110W_wave = F.wavelength[284338:302340]\n",
    "    F.WFC3IR_F110W = F.response[284338:302340]\n",
    "    F.WFC3IR_F125W_wave = F.wavelength[302340:311340]\n",
    "    F.WFC3IR_F125W = F.response[302340:311340]\n",
    "    F.WFC3IR_F140W_wave = F.wavelength[311340:320341]\n",
    "    F.WFC3IR_F140W = F.response[311340:320341]\n",
    "    F.WFC3IR_F160W_wave = F.wavelength[320341:329342]\n",
    "    F.WFC3IR_F160W = F.response[320341:329342]\n",
    "    F.IRAC_1_wave = F.wavelength[329342:329847]\n",
    "    F.IRAC_1 = F.response[329342:329847]\n",
    "    F.IRAC_2_wave = F.wavelength[329847:330274]\n",
    "    F.IRAC_2 = F.response[329847:330274]\n",
    "    F.IRAC_3_wave = F.wavelength[330274:330644]\n",
    "    F.IRAC_3 = F.response[330274:330644]\n",
    "    F.IRAC_4_wave = F.wavelength[330644:331065]\n",
    "    F.IRAC_4 = F.response[330644:331065]\n",
    "    F.ISAAC_Ks_wave = F.wavelength[331065:331265]\n",
    "    F.ISAAC_Ks = F.response[331065:331265]\n",
    "    F.FORS_V_wave = F.wavelength[331265:331765]\n",
    "    F.FORS_V = F.response[331265:331765]\n",
    "    F.FORS_R_wave = F.wavelength[331765:332265]\n",
    "    F.FORS_R = F.response[331765:332265]\t\n",
    "    F.NIC_F110W_wave = F.wavelength[332265:334264]\n",
    "    F.NIC_F110W = F.response[332265:334264]\t\n",
    "    F.NIC_F160W_wave = F.wavelength[334264:335868]\n",
    "    F.NIC_F160W = F.response[334264:335868]\t\n",
    "    F.GALEX_FUV_wave = F.wavelength[335868:336369]\n",
    "    F.GALEX_FUV = F.response[335868:336369]\t\n",
    "    F.GALEX_NUV_wave = F.wavelength[335868:337710]\n",
    "    F.GALEX_NUV = F.response[335868:337710]\n",
    "    F.DES_g_wave = F.wavelength[337710:337900]\n",
    "    F.DES_g = F.response[337710:337900]\t\n",
    "    F.DES_r_wave = F.wavelength[337900:338100]\n",
    "    F.DES_r = F.response[337900:338100]\t\n",
    "    F.DES_i_wave = F.wavelength[338100:338290]\n",
    "    F.DES_i = F.response[338100:338290]\n",
    "    F.DES_z_wave = F.wavelength[338290:338480]\n",
    "    F.DES_z = F.response[338290:338480]\n",
    "    F.DES_Y_wave = F.wavelength[338480:338570]\n",
    "    F.DES_Y = F.response[338480:338570]\n",
    "    F.WFCAM_Z_wave = F.wavelength[338570:338723]\n",
    "    F.WFCAM_Z = F.response[338570:338723]\n",
    "    F.WFCAM_Y_wave = F.wavelength[338723:338890]\n",
    "    F.WFCAM_Y = F.response[338723:338890]\n",
    "    F.WFCAM_J_wave = F.wavelength[338890:339139]\n",
    "    F.WFCAM_J = F.response[338890:339139]\n",
    "    F.WFCAM_H_wave = F.wavelength[339139:339642]\n",
    "    F.WFCAM_H = F.response[339139:339642]\n",
    "    F.WFCAM_K_wave = F.wavelength[339642:340216]\n",
    "    F.WFCAM_K = F.response[339642:340216]\n",
    "    F.Steidel_Un_wave = F.wavelength[340216:340259]\n",
    "    F.Steidel_Un = F.response[340216:340259]\n",
    "    F.Steidel_G_wave = F.wavelength[340259:340430]\n",
    "    F.Steidel_G = F.response[340259:340430]\n",
    "    F.Steidel_Rs_wave = F.wavelength[340430:341239]\n",
    "    F.Steidel_Rs = F.response[340430:341239]\n",
    "    F.Steidel_I_wave = F.wavelength[341239:341636]\n",
    "    F.Steidel_I = F.response[341239:341636]\n",
    "    F.MegaCam_u_wave = F.wavelength[341636:341768]\n",
    "    F.MegaCam_u = F.response[341636:341768]\n",
    "    F.MegaCam_g_wave = F.wavelength[341768:342009]\n",
    "    F.MegaCam_g = F.response[341768:342009]\n",
    "    F.MegaCam_r_wave = F.wavelength[342009:342239]\n",
    "    F.MegaCam_r = F.response[342009:342239]\n",
    "    F.MegaCam_i_wave = F.wavelength[342239:342378]\n",
    "    F.MegaCam_i = F.response[342239:342378]\n",
    "    F.MegaCam_z_wave = F.wavelength[342378:342530]\n",
    "    F.MegaCam_z = F.response[342378:342530]\n",
    "    F.WISE_W1_wave = F.wavelength[342530:342717]\n",
    "    F.WISE_W1 = F.response[342530:342717]\n",
    "    F.WISE_W2_wave = F.wavelength[342717:342967]\n",
    "    F.WISE_W2 = F.response[342717:342967]\n",
    "    F.WISE_W3_wave = F.wavelength[342967:344467]\n",
    "    F.WISE_W3 = F.response[342967:344467]\n",
    "    F.WISE_W4_wave = F.wavelength[344467:345679]\n",
    "    F.WISE_W4 = F.response[344467:345679]\n",
    "    F.UVOT_w2_wave = F.wavelength[345679:346320]\n",
    "    F.UVOT_w2 = F.response[345679:346320]\n",
    "    F.UVOT_m2_wave = F.wavelength[346320:346636]\n",
    "    F.UVOT_m2 = F.response[346320:346636]\n",
    "    F.UVOT_w1_wave = F.wavelength[346636:347177]\n",
    "    F.UVOT_w1 = F.response[346636:347177]\n",
    "    F.MIPS_24um_wave = F.wavelength[347177:347305]\n",
    "    F.MIPS_24um = F.response[347177:347305]\n",
    "    F.MIPS_70um_wave = F.wavelength[347305:347416]\n",
    "    F.MIPS_70um = F.response[347305:347416]\n",
    "    F.MIPS_160um_wave = F.wavelength[347416:347815]\n",
    "    F.MIPS_160um = F.response[347416:347815]\n",
    "    F.SCUBA_450WB_wave = F.wavelength[347815:348511]\n",
    "    F.SCUBA_450WB = F.response[347815:348511]\n",
    "    F.SCUBA_850WB_wave = F.wavelength[348511:348994]\n",
    "    F.SCUBA_850WB = F.response[348511:348994]\n",
    "    F.PACS_70um_wave = F.wavelength[348994:349208]\n",
    "    F.PACS_70um = F.response[348994:349208]\n",
    "    F.PACS_100um_wave = F.wavelength[349208:349447]\n",
    "    F.PACS_100um = F.response[349208:349447]\n",
    "    F.PACS_160um_wave = F.wavelength[349447:349680]\n",
    "    F.PACS_160um = F.response[349447:349680]\n",
    "    F.SPIRE_250um_wave = F.wavelength[349680:349810]\n",
    "    F.SPIRE_250um = F.response[349680:349810]\n",
    "    F.SPIRE_350um_wave = F.wavelength[349810:349901]\n",
    "    F.SPIRE_350um = F.response[349810:349901]\n",
    "    F.SPIRE_500um_wave = F.wavelength[349901:349999]\n",
    "    F.SPIRE_500um = F.response[349901:349999]\n",
    "    F.IRAS_12um_wave = F.wavelength[349999:350017]\n",
    "    F.IRAS_12um = F.response[349999:350017]\n",
    "    F.IRAS_25um_wave = F.wavelength[350017:350049]\n",
    "    F.IRAS_25um = F.response[350017:350049]\n",
    "    F.IRAS_60um_wave = F.wavelength[350049:350070]\n",
    "    F.IRAS_60um = F.response[350049:350070]\n",
    "    F.IRAS_100um_wave = F.wavelength[350070:350086]\n",
    "    F.IRAS_100um = F.response[350070:350086]\n",
    "    F.Bessel_L_wave = F.wavelength[350086:350107]\n",
    "    F.Bessel_L = F.response[350086:350107]\n",
    "    F.Bessel_Lprime_wave = F.wavelength[350107:350127]\n",
    "    F.Bessel_Lprime = F.response[350107:350127]\n",
    "    F.Bessel_M_wave = F.wavelength[350127:350144]\n",
    "    F.Bessel_M = F.response[350127:350144]\n",
    "    F.Stromgren_u_wave = F.wavelength[350144:350173]\n",
    "    F.Stromgren_u = F.response[350144:350173]\n",
    "    F.Stromgren_v_wave = F.wavelength[350173:350202]\n",
    "    F.Stromgren_v = F.response[350173:350202]\n",
    "    F.Stromgren_b_wave = F.wavelength[350202:350231]\n",
    "    F.Stromgren_b = F.response[350202:350231]\n",
    "    F.Stromgren_y_wave = F.wavelength[350231:350260]\n",
    "    F.Stromgren_y = F.response[350231:350260]\n",
    "    F.Idealized_1500A_wave = F.wavelength[350260:350301]\n",
    "    F.Idealized_1500A = F.response[350260:350301]\n",
    "    F.Idealized_2300A_wave = F.wavelength[350301:350362]\n",
    "    F.Idealized_2300A = F.response[350301:350362]\n",
    "    F.Idealized_2800A_wave = F.wavelength[350362:350437]\n",
    "    F.Idealized_2800A = F.response[350362:350437]\n",
    "    F.JWST_F070W_wave = F.wavelength[350437:350837]\n",
    "    F.JWST_F070W = F.response[350437:350837]\n",
    "    F.JWST_F090W_wave = F.wavelength[350837:351139]\n",
    "    F.JWST_F090W = F.response[350837:351139]\n",
    "    F.JWST_F115W_wave = F.wavelength[351139:351555]\n",
    "    F.JWST_F115W = F.response[351139:351555]\n",
    "    F.JWST_F150W_wave = F.wavelength[351555:352221]\n",
    "    F.JWST_F150W = F.response[35155:352221]\n",
    "    F.JWST_F200W_wave = F.wavelength[352221:353128]\n",
    "    F.JWST_F200W = F.response[352221:353128]\n",
    "    F.JWST_F277W_wave = F.wavelength[353128:354553]\n",
    "    F.JWST_F277W = F.response[353128:354553]\n",
    "    F.JWST_F356W_wave = F.wavelength[354553:355899]\n",
    "    F.JWST_F356W = F.response[354553:355899]\n",
    "    F.JWST_F444W_wave = F.wavelength[355899:357351]\n",
    "    F.JWST_F444W = F.response[355899:357351]\n",
    "    F.NEWFIRM_J1_wave = F.wavelength[357351:357447]\n",
    "    F.NEWFIRM_J1 = F.response[357351:357447]\n",
    "    F.NEWFIRM_J2_wave = F.wavelength[357447:357526]\n",
    "    F.NEWFIRM_J2 = F.response[357447:357526]\n",
    "    F.NEWFIRM_J3_wave = F.wavelength[357526:357599]\n",
    "    F.NEWFIRM_J3 = F.response[357526:357599]\n",
    "    F.NEWFIRM_H1_wave = F.wavelength[357599:357669]\n",
    "    F.NEWFIRM_H1 = F.response[357599:357669]\n",
    "    F.NEWFIRM_H2_wave = F.wavelength[357669:357733]\n",
    "    F.NEWFIRM_H2 = F.response[357669:357733]\n",
    "    F.NEWFIRM_K_wave = F.wavelength[357733:357798]\n",
    "    F.NEWFIRM_K = F.response[357733:357798]\n",
    "    F.VIRCAM_Y_wave = F.wavelength[357798:357914]\n",
    "    F.VIRCAM_Y = F.response[357798:357914]\n",
    "    F.VIRCAM_J_wave = F.wavelength[357914:358062]\n",
    "    F.VIRCAM_J = F.response[357914:358062]\n",
    "    F.VIRCAM_H_wave = F.wavelength[358062:358286]\n",
    "    F.VIRCAM_H = F.response[358062:358286]\n",
    "    F.VIRCAM_K_wave = F.wavelength[358286:358545]\n",
    "    F.VIRCAM_K = F.response[358286:358545]\n",
    "    F.SuprimeCam_B_wave = F.wavelength[358545:358735]\n",
    "    F.SuprimeCam_B = F.response[358545:358735]\n",
    "    F.SuprimeCam_gplus_wave = F.wavelength[358735:358925]\n",
    "    F.SuprimeCam_gplus = F.response[358735:358925]\n",
    "    F.SuprimeCam_V_wave = F.wavelength[358925:359111]\n",
    "    F.SuprimeCam_V = F.response[358925:359111]\n",
    "    F.SuprimeCam_rplus_wave = F.wavelength[359111:359300]\n",
    "    F.SuprimeCam_rplus = F.response[359111:359300]\n",
    "    F.SuprimeCam_iplus_wave = F.wavelength[359300:359518]\n",
    "    F.SuprimeCam_iplus = F.response[359300:359518]\n",
    "    F.SuprimeCam_zplus_wave = F.wavelength[359518:359703]\n",
    "    F.SuprimeCam_zplus = F.response[359518:359703]\n",
    "    F.PanSTARRS1_g_wave = F.wavelength[359703:359882]\n",
    "    F.PanSTARRS1_g = F.response[359703:359882]\n",
    "    F.PanSTARRS1_r_wave = F.wavelength[359882:360069]\n",
    "    F.PanSTARRS1_r = F.response[359882:360069]\n",
    "    F.PanSTARRS1_i_wave = F.wavelength[360069:360250]\n",
    "    F.PanSTARRS1_i = F.response[360069:360250]\n",
    "    F.PanSTARRS1_z_wave = F.wavelength[360250:360418]\n",
    "    F.PanSTARRS1_z = F.response[360250:360418]\n",
    "    F.PanSTARRS1_y_wave = F.wavelength[360418:360624]\n",
    "    F.PanSTARRS1_y = F.response[360418:360624]\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_distance(z, h0=73., omega_m=0.27, omega_l=0.73):\n",
    "    \n",
    "    '''\n",
    "    Computing luminosity distance\n",
    "    Input:  - z (float) -- redshift\n",
    "            - h0 (float) (optional) -- hubble constant (in km/pc)\n",
    "            - omega_m (float) (optional) -- matter density parameter\n",
    "            - omega_l (float) (optional) -- dark energy density parameter\n",
    "            \n",
    "    Output: - luminosity distance (float) -- in parsec\n",
    "    '''\n",
    "    \n",
    "    c = 2.9979e18 #velocity of lights\n",
    "    omega_k = 1. - omega_m - omega_l\n",
    "    dh = c/1.e13/h0 * 1.e6 #in pc\n",
    "    \n",
    "    if z > 0.:\n",
    "        dc, edc = integrate.quad(lambda x: (omega_m * (1.+x)** 3 + omega_k * (1+x)**2 + omega_l)**(-.5), 0., z, epsrel=1e-4)\n",
    "        dc = dh * dc\n",
    "    else:\n",
    "    # Bad idea as there is something *wrong* going on\n",
    "        print('LumDist: z <= 0 -> Assume z = 0!')\n",
    "        z = 0.\n",
    "        #dist = 0.\n",
    "        return 0\n",
    "    \n",
    "    if omega_k > 0.:\n",
    "    \tdm = dh * np.sinh(dc/dh * np.sqrt(omega_k)) / np.sqrt(omega_k)\n",
    "    elif omega_k < 0.:\n",
    "    \tdm = dh * np.sin(dc/dh * np.sqrt(-omega_k)) / np.sqrt(-omega_k)\n",
    "    else:\n",
    "    \tdm = dc\n",
    "    return dm * (1+z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doppler_shift(wavelength, luminosity, z): #wavelength in micrometer\n",
    "    '''\n",
    "    Shifting intrinsic spectrum to observed spectrum using doppler shift formula\n",
    "    Input:  - wavelength (list(float)) -- wavelength (in Angstorm)\n",
    "            - luminosity (list(list(float))) -- intrinsic luminosity of each galaxy in each wavelength\n",
    "            - z -- intrinsic redshift\n",
    "            \n",
    "    Output: - wavelength (list(float)) -- redshifted wavelength (in Angstorm)\n",
    "            - luminosity (list(list(float))) -- observed luminosity (in erg/cm2/s/AA)\n",
    "    '''\n",
    "    \n",
    "    pc2cm = 3.0856e18\n",
    "    solar_lum = 3.839e33 # in cgs\n",
    "    if z == 0:\n",
    "    \tdistance = 10 * pc2cm #distance in cm: 1pc = 3.0856e18 cm\n",
    "    else:\n",
    "    \twavelength = wavelength * (1. + z)\n",
    "    \tdistance = luminosity_distance(z) * pc2cm #distance in cm: 1pc = 3.0856e18 cm\n",
    "    spectrum = luminosity * solar_lum / (4*np.pi*distance**2) #spec in erg/cm2/s/AA \n",
    "    return (wavelength, spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_individual_mab(wavelength, luminosity, filt_wave, filt, z):\n",
    "    \n",
    "    '''\n",
    "    Compute AB magnitude (mAB) using a single filter\n",
    "    Input:  - wavelength (list(float)) -- intrinsic wavelength (in Angstorm)\n",
    "            - luminosity (list(list(float))) -- intrinsic luminosity (in erg/cm2/s/AA)\n",
    "            - filt_wave (str) -- name of the variable of filter wavelength (from the list)\n",
    "            - filt (str) -- name of the filter (from the list)\n",
    "            - z (float) -- redshift\n",
    "            \n",
    "    Output: - AB magnitude (float) of the input filter\n",
    "    '''\n",
    "    \n",
    "    from scipy.integrate import simps\n",
    "    c = 2.9979e18\n",
    "    wavelength, spectrum = doppler_shift(wavelength, luminosity, z)\n",
    "    filt_int  = np.interp(wavelength, filt_wave, filt)\n",
    "    filtSpec = filt_int * spectrum\n",
    "    flux = simps(filtSpec, wavelength)\n",
    "    I1 = simps(spectrum*filt_int*wavelength,wavelength)\n",
    "    I2 = simps(filt_int/wavelength, wavelength) \n",
    "    fnu = I1/I2/c\n",
    "    mAB = -2.5*np.log10(fnu) - 48.6\n",
    "    return(mAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mab(wavelength, luminosity, filter_list, z):\n",
    "    '''\n",
    "    Compute mab from a list of filters\n",
    "    Input : - wavelength (list(float)) -- intrinsic wavelength (in Angstorm)\n",
    "            - luminosity (list(list(float))) -- intrinsic luminosity (in erg/cm2/s/AA)\n",
    "            - filter_list (list(str)) -- list of filter name\n",
    "            - z (float) -- redshift\n",
    "            \n",
    "    Output: - AB magnitude (list(float)) -- computed AB magnitude of the input filters\n",
    "    \n",
    "    '''\n",
    "    F = read_filters()\n",
    "    mab_list = []\n",
    "    for i in range(len(filter_list)):\n",
    "    \tfilters_wave = eval('F.' + filter_list[i] + '_wave')\n",
    "    \tfilters = eval('F.' + filter_list[i])\n",
    "    \tmab = compute_individual_mab(wavelength, luminosity, filters_wave, filters, z)\n",
    "    \tmab_list.append(mab)\n",
    "    return(mab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tree-by-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hubble_h = 0.73\n",
    "directory_dusty = \"../dusty-sage/src/auxdata/trees/save-stellar-DTG/\"\n",
    "SAM_choice = 1 #0: sage, 1:dustysage\n",
    "firstfile = 0\n",
    "lastfile = 0\n",
    "snap_limit = 63\n",
    "\n",
    "Age = np.asarray([0.0124, 0.0246, 0.0491, 0.1037, 0.1871, 0.2120, 0.2399, 0.2709, 0.3054, 0.3438, 0.3864, 0.4335, 0.4856, 0.5430, 0.6062, 0.6756, 0.7517, 0.8349, 0.9259, 1.0249, 1.1327, 1.2496, 1.3763, 1.5131, 1.6606, 1.8192, 1.9895, 2.1717, 2.3662, 2.5734, 2.7934, 3.0265, 3.2726, 3.5318, 3.8038, 4.0886, 4.3856, 4.6944, 5.0144, 5.3488, 5.6849, 6.0337, 6.3901, 6.7531, 7.1215, 7.4940, 7.8694, 8.2464, 8.6238, 9.0004, 9.3750, 9.7463, 10.1133, 10.4750, 10.8303, 11.1783, 11.5181, 11.8490, 12.1702, 12.4811, 12.7810, 13.0695, 13.3459, 13.6098])\n",
    "lookbacktime = sorted((np.array([13.6098]*len(Age)) - Age) * 1.e9)\n",
    "time_BC = 10**7\n",
    "\n",
    "Mass_arr = []\n",
    "Dust_arr = []\n",
    "Spectra_arr = []\n",
    "\n",
    "for tree in iterate_trees(SAM_choice, directory_dusty, firstfile, lastfile):\n",
    "    \n",
    "    mass, metals = calculate_mass_and_metals(SAM_choice, tree, snap_limit)\n",
    "    dust, gas_metal, gas, rad = calculate_dust_density(tree)\n",
    "\n",
    "    w = np.where((mass[:,snap_limit] > 0) & (dust[:,snap_limit] > 0))[0]\n",
    "    if len(w) > 0:\n",
    "        print(len(w))\n",
    "        Mass = mass[w] / Hubble_h \n",
    "        Metals = metals[w]\n",
    "\n",
    "        Mass_arr.extend(Mass)\n",
    "\n",
    "        Dust = dust[w,snap_limit] / Hubble_h\n",
    "        Gas = gas[w,snap_limit] / Hubble_h\n",
    "        Rad = rad[w,snap_limit] / Hubble_h\n",
    "\n",
    "        Dust_arr.extend(Dust)\n",
    "\n",
    "        eta_BC = [-0.7] * len(Dust)\n",
    "        #eta_ISM_v2 = [-1.3] * len(Dust)\n",
    "        Sigma_BC, tau_head_BC = compute_tau_BC(Dust, Gas, Rad)\n",
    "        Sigma_tau_ISM, tau_head_ISM = compute_tau_ISM(Dust, Gas, Rad)\n",
    "        Sigma_eta_ISM, eta_ISM = compute_eta_ISM(Dust, Gas, Rad)\n",
    "\n",
    "        #Sigma_ISM_v2, tau_ISM_v2 = compute_tau_ISM_v2 (Dust, Rad)\n",
    "        #Sigma_BC_v2, tau_BC_v2 = compute_tau_BC_v2 (Dust, Rad)\n",
    "\n",
    "        wavelength, spectra, spectra_dusty = generate_SED(SAM_choice, Age, Mass, Metals, \n",
    "                 tau_head_BC, tau_head_ISM, eta_BC, eta_ISM, time_BC)\n",
    "        \n",
    "        full_wavelength, full_spectra = add_IR_Dale(wavelength, spectra, spectra_dusty)\n",
    "        Spectra_arr.extend(full_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mass = np.array(Mass_arr)\n",
    "Dust = np.array(Dust_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running and Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = \"mini-millennium/\"\n",
    "directory_dusty = \"../dusty-sage/src/auxdata/trees/save-stellar-DTG/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hubble_h = 0.73\n",
    "\n",
    "BoxSize = ((62.5**3) * (1/8))**(1/3) #mini-millennium\n",
    "#BoxSize = ((500**3) * (512/512))**(1/3) #full-millennium\n",
    "#BoxSize = ((1000**3) * (1000/1000))**(1/3) #MDPL\n",
    "#BoxSize = ((250**3) * (1/125))**(1/3) #bolshoi\n",
    "\n",
    "dilute = 5000\n",
    "sSFRcut = -11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = '../../output/test-bulge3/'\n",
    "directory_dusty = '../dusty-sage/src/auxdata/trees/save-stellar-DTG/'\n",
    "directory = \"mini-millennium/\"\n",
    "filename = 'model'\n",
    "Age = np.asarray([0.0124, 0.0246, 0.0491, 0.1037, 0.1871, 0.2120, 0.2399, 0.2709, 0.3054, 0.3438, 0.3864, 0.4335, 0.4856, 0.5430, 0.6062, 0.6756, 0.7517, 0.8349, 0.9259, 1.0249, 1.1327, 1.2496, 1.3763, 1.5131, 1.6606, 1.8192, 1.9895, 2.1717, 2.3662, 2.5734, 2.7934, 3.0265, 3.2726, 3.5318, 3.8038, 4.0886, 4.3856, 4.6944, 5.0144, 5.3488, 5.6849, 6.0337, 6.3901, 6.7531, 7.1215, 7.4940, 7.8694, 8.2464, 8.6238, 9.0004, 9.3750, 9.7463, 10.1133, 10.4750, 10.8303, 11.1783, 11.5181, 11.8490, 12.1702, 12.4811, 12.7810, 13.0695, 13.3459, 13.6098])\n",
    "#redshift = [127.000, 79.998, 50.000, 30.000, 19.916, 18.244, 16.725, 15.343, 14.086, 12.941, 11.897, 10.944, 10.073, 9.278, 8.550, 7.883, 7.272, 6.712, 6.197, 5.724, 5.289, 4.888, 4.520, 4.179, 3.866, 3.576, 3.308, 3.060, 2.831, 2.619, 2.422, 2.239, 2.070, 1.913, 1.766, 1.630, 1.504, 1.386, 1.276, 1.173, 1.078, 0.989, 0.905, 0.828, 0.755, 0.687, 0.624, 0.564, 0.509, 0.457, 0.408, 0.362, 0.320, 0.280, 0.242, 0.208, 0.175, 0.144, 0.116, 0.089, 0.064, 0.041, 0.020, 0.000]\n",
    "#redshift.reverse()\n",
    "#age_list = cosmo.age(redshift).value\n",
    "#lbtime = cosmo.lookback_time(redshift).value\n",
    "redshift = [0.000, 1.386, 2.070, 3.060, 4.179, 5.289, 6.197, 7.272] #millennium \n",
    "#redshift = [0.024, 1.309, 2.051, 3.033, 4.088, 5.127, 6.044, 7.098] #genesis\n",
    "#redshift = [0.000, 1.379, 2.028, 3.060, 4.043, 5.161, 6.231, 7.313] #bolshoi\n",
    "#redshift = [0.000]\n",
    "#redshift = [0.000, 1.321, 2.028, 3.037, 4.038, 5.150, 6.022, 7.026] #MDPL\n",
    "firstfile = 0\n",
    "lastfile = 0\n",
    "MaxTreeFiles = lastfile - firstfile + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_file(name, Galdesc):\n",
    "    '''\n",
    "    Read each output file and store based on galaxy propertiest listed in galdtype or galdtype_dusty\n",
    "    '''\n",
    "    fin = open(name, 'rb')\n",
    "    Ntrees = np.fromfile(fin,np.dtype(np.int32),1)[0]\n",
    "    NtotGals = np.fromfile(fin,np.dtype(np.int32),1)[0]\n",
    "    GalsPerTree = np.fromfile(fin, np.dtype((np.int32, Ntrees)),1)[0]\n",
    "    G = np.fromfile(fin, Galdesc, NtotGals)\n",
    "    G = G.view(recarray)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Galdesc = galdtype(align=True)\n",
    "Galdesc_dusty = galdtype_dusty(align=True)\n",
    "\n",
    "G_history = [0]*len(redshift)\n",
    "G_history_dusty = [0]*len(redshift)\n",
    "\n",
    "for i in range(len(redshift)):\n",
    "    G_snap = []\n",
    "    G_snap_dusty = []\n",
    "    GalsTree = []\n",
    "    \n",
    "    for k in range(firstfile, lastfile+1):\n",
    "                \n",
    "        name = (directory+filename+'_z'+f'{redshift[i]:.3f}'+'_'+f'{k}')\n",
    "        G = read_one_file(name, Galdesc)\n",
    "        G_snap.extend(G)\n",
    "                \n",
    "        name_dusty = (directory_dusty+filename+'_z'+f'{redshift[i]:.3f}'+'_'+f'{k}')\n",
    "        G_dusty = read_one_file(name_dusty, Galdesc_dusty)\n",
    "        G_snap_dusty.extend(G_dusty)\n",
    "        \n",
    "    G_snap = np.array(G_snap)\n",
    "    G_snap = G_snap.view(recarray)\n",
    "    G_history[i] = G_snap\n",
    "    \n",
    "    G_snap_dusty = np.array(G_snap_dusty)\n",
    "    G_snap_dusty = G_snap_dusty.view(recarray)\n",
    "    G_history_dusty[i] = G_snap_dusty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_limit = 63\n",
    "#mass_sage, metals_sage = build_mass_and_metallicity_history(0, directory, firstfile, lastfile, snap_limit)\n",
    "mass_dusty, metals_dusty  = build_mass_and_metallicity_history(1, directory_dusty, firstfile, lastfile, snap_limit)\n",
    "dust, gas_metals, gas, rad  = build_dust_history(1, directory_dusty, firstfile, lastfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ldust = (spectra[0] - spectra_dusty[0])\n",
    "w = np.where(wavelength < 912)[0]\n",
    "idx_912 = w[-1]\n",
    "print(wavelength[idx_912], wavelength[0])\n",
    "LIR_mentari = trapz(Ldust[idx_912:-1], wavelength[idx_912:-1])\n",
    "LIR = trapz(Ldust, wavelength)\n",
    "print(LIR_mentari, LIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstfile = 0\n",
    "lastfile = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 %.....................10 %.....................20 %.....................30 %.....................40 %.....................50 %.....................60 %.....................70 %.....................80 %.....................90 %.....................0 %.....................10 %.....................20 %.....................30 %.....................40 %.....................50 %.....................60 %.....................70 %.....................80 %.....................90 %.....................0 %.....................10 %.....................20 %.....................30 %.....................40 %.....................50 %.....................60 %.....................70 %.....................80 %.....................90 %....................."
     ]
    }
   ],
   "source": [
    "for i in range(firstfile, lastfile+1):\n",
    "    print(i)\n",
    "    output = \"output/mentari_output_v2_\" + str(i) + \".hdf5\"\n",
    "    if os.path.isfile(output) == 0:\n",
    "        \n",
    "        mass_dusty, metals_dusty = mtr.build_mass_and_metallicity_history(1, directory_dusty, i, i, snap_limit)\n",
    "        dust, gas_metals, gas, rad  = mtr.build_dust_history(1, directory_dusty, i, i, snap_limit)\n",
    "\n",
    "        #Compute attenuation parameters\n",
    "        w = np.where((mass_dusty[:,snap_limit] > 0) & (dust[:,snap_limit] > 0))[0]\n",
    "        Mass = mass_dusty[w] / Hubble_h \n",
    "        Metals = metals_dusty[w]\n",
    "\n",
    "        Dust = dust[w,snap_limit] / Hubble_h\n",
    "        Gas = gas[w,snap_limit] / Hubble_h\n",
    "        Rad = rad[w,snap_limit] / Hubble_h\n",
    "\n",
    "        prescription = 0 #0 for Lagos+ 19; 1 for Somerville+ 12\n",
    "        tau_BC, eta_BC, tau_ISM, eta_ISM = mtr.compute_attenuation_parameters (prescription, Dust, Gas, Rad)\n",
    "\n",
    "        #Model Variants 1: Lagos + Dale + Safarzadeh\n",
    "        time_BC = 10**7\n",
    "        SSP = 0 #0 for BC03 \n",
    "        wavelength, spectra, spectra_dusty = mtr.generate_SED(0, Age, Mass, Metals, \n",
    "                     tau_BC, tau_ISM, eta_BC, eta_ISM, time_BC)\n",
    "\n",
    "        wavelength_m1, spectra_m1 = mtr.combine_Dale_SUNRISE(Dust, wavelength, spectra, spectra_dusty)\n",
    "\n",
    "        #Model Variants 2: Lagos + Dale\n",
    "        wavelength_m2, spectra_m2 = mtr.add_IR_Dale(wavelength, spectra, spectra_dusty)\n",
    "\n",
    "        #Model Variants 3: Somerville + Dale + Safarzadeh\n",
    "        prescription = 1 #0 for Lagos+ 19; 1 for Somerville+ 12\n",
    "        tau_BC_s, eta_BC_s, tau_ISM_s, eta_ISM_s = mtr.compute_attenuation_parameters (prescription, Dust, Gas, Rad)\n",
    "        wavelength_s, spectra_s, spectra_dusty_s = mtr.generate_SED(0, Age, Mass, Metals, tau_BC_s, tau_ISM_s, eta_BC_s, eta_ISM_s, time_BC)\n",
    "\n",
    "        wavelength_m3, spectra_m3 = mtr.combine_Dale_SUNRISE(Dust, wavelength_s, spectra_s, spectra_dusty_s)\n",
    "\n",
    "        #Model Variants 4: CF00 + Dale + Safarzadeh\n",
    "        tau_BC_cf = 1.0\n",
    "        eta_BC_cf = -0.7\n",
    "        tau_ISM_cf = 0.3\n",
    "        eta_ISM_cf = -0.7\n",
    "        wavelength_cf, spectra_cf, spectra_dusty_cf = mtr.generate_SED(0, Age, Mass, Metals, \n",
    "                     tau_BC_cf, tau_ISM_cf, eta_BC_cf, eta_ISM_cf, time_BC)\n",
    "\n",
    "        wavelength_m4, spectra_m4 = mtr.combine_Dale_SUNRISE(Dust, wavelength_cf, spectra_cf, spectra_dusty_cf)\n",
    "\n",
    "        with h5py.File(output, 'w') as f:\n",
    "            f.create_dataset('StellarMass', data=Mass)\n",
    "            f.create_dataset('Metallicity', data=Metals)\n",
    "            f.create_dataset('DustMass', data=Dust)\n",
    "            f.create_dataset('GasMass', data=Gas)\n",
    "            f.create_dataset('Radius', data=Rad)\n",
    "            f.create_dataset('Wavelength_m1', data=wavelength_m1)\n",
    "            f.create_dataset('Spectra_m1', data=spectra_m1)\n",
    "            f.create_dataset('Wavelength_m2', data=wavelength_m2)\n",
    "            f.create_dataset('Spectra_m2', data=spectra_m2)\n",
    "            f.create_dataset('Wavelength_m3', data=wavelength_m3)\n",
    "            f.create_dataset('Spectra_m3', data=spectra_m3)\n",
    "            f.create_dataset('Wavelength_m4', data=wavelength_m4)\n",
    "            f.create_dataset('Spectra_m4', data=spectra_m4)\n",
    "            f.create_dataset('Wavelength_stellar', data=wavelength)\n",
    "            f.create_dataset('Spectra_stellar', data=spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/mentari_output_0.hdf5\n"
     ]
    }
   ],
   "source": [
    "mass_dusty = []\n",
    "metals_dusty = []\n",
    "wavelength_m1 = []\n",
    "spectra_m1 = []\n",
    "wavelength_m2 = []\n",
    "spectra_m2 = []\n",
    "wavelength_m3 = []\n",
    "spectra_m3 = []\n",
    "wavelength_m4 = []\n",
    "spectra_m4 = []\n",
    "\n",
    "dirname = 'output/'\n",
    "filename = 'mentari_output_'\n",
    "ext = '.hdf5'\n",
    "firstfile = 0\n",
    "lastfile = 0\n",
    "\n",
    "for i in range(firstfile, lastfile+1):\n",
    "    file = dirname + filename + str(i) + ext\n",
    "    print (file)\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        mass_dusty.extend(f['StellarMass'])\n",
    "        metals_dusty.extend(f['Metallicity'])\n",
    "        wavelength_m1.extend(f['Wavelength_m1'])\n",
    "        spectra_m1.extend(f['Spectra_m1'])\n",
    "        wavelength_m2.extend(f['Wavelength_m2'])\n",
    "        spectra_m2.extend(f['Spectra_m2'])\n",
    "        wavelength_m3.extend(f['Wavelength_m3'])\n",
    "        spectra_m3.extend(f['Spectra_m3'])\n",
    "        wavelength_m4.extend(f['Wavelength_m4'])\n",
    "        spectra_m4.extend(f['Spectra_m4'])\n",
    "        \n",
    "mass_dusty = np.array(mass_dusty)\n",
    "metals_dusty = np.array(metals_dusty)\n",
    "spectra_m1 = np.array(spectra_m1)\n",
    "wavelength_m1 = np.array(wavelength_m1)\n",
    "spectra_m2 = np.array(spectra_m2)\n",
    "wavelength_m2 = np.array(wavelength_m2)\n",
    "spectra_m3 = np.array(spectra_m3)\n",
    "wavelength_m3 = np.array(wavelength_m3)\n",
    "spectra_m4 = np.array(spectra_m4)\n",
    "wavelength_m4 = np.array(wavelength_m4)\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(firstfile, lastfile+1):\n",
    "    print(i)\n",
    "    \n",
    "    mass_dusty, metals_dusty = build_mass_and_metallicity_history(1, directory_dusty, i, i, snap_limit)\n",
    "    dust, gas_metals, gas, rad  = build_dust_history(1, directory_dusty, i, i)\n",
    "\n",
    "    #Compute attenuation parameters\n",
    "    w = np.where(mass_dusty[:,snap_limit] > 0)[0]\n",
    "    \n",
    "    Mass = mass_dusty[w] / Hubble_h \n",
    "    Metals = metals_dusty[w]\n",
    "    Dust = dust[w,snap_limit] / Hubble_h\n",
    "    Gas = gas[w,snap_limit] / Hubble_h\n",
    "    Rad = rad[w,snap_limit] / Hubble_h\n",
    "\n",
    "    prescription = 0 #0 for Lagos+ 19; 1 for Somerville+ 12\n",
    "    tau_BC, eta_BC, tau_ISM, eta_ISM = compute_attenuation_parameters (prescription, Dust, Gas, Rad)\n",
    "\n",
    "    time_BC = 10**7\n",
    "    SSP = 0 #0 for BC03 \n",
    "    wavelength, spectra, spectra_dusty = generate_SED(0, Age, Mass, Metals, \n",
    "                 tau_BC, tau_ISM, eta_BC, eta_ISM, time_BC)\n",
    "    wavelength_IR, spectra_IR = add_IR_Dale(wavelength, spectra, spectra_dusty)\n",
    "    \n",
    "    output = \"output/mentari_output_\" + str(i) + \".hdf5\"\n",
    "    with h5py.File(output, 'w') as f:\n",
    "        f.create_dataset('StellarMass', data=Mass, maxshape=(None,snap_limit+1), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Metallicity', data=Metals, maxshape=(None,snap_limit+1), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('DustMass', data=Dust, maxshape=(None,), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('GasMass', data=Gas, maxshape=(None,), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Radius', data=Rad, maxshape=(None,), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Wavelength_UVIR', data=wavelength_IR, maxshape=(None,), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Spectra_UVIR', data=spectra_IR, maxshape=(None,len(wavelength_IR)), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Wavelength_stellar', data=wavelength, maxshape=(None,), chunks=True, compression=\"gzip\")\n",
    "        f.create_dataset('Spectra_stellar', data=spectra, maxshape=(None,len(wavelength)), chunks=True, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dusty = []\n",
    "metals_dusty = []\n",
    "wavelength = []\n",
    "spectra = []\n",
    "\n",
    "filename = ['output/mentari_output_0.hdf5', 'output/mentari_output_1.hdf5']\n",
    "for i in filename:\n",
    "    f = h5py.File(i, 'r')\n",
    "    mass_dusty.extend(f['StellarMass'])\n",
    "    metals_dusty.extend(f['Metallicity'])\n",
    "    wavelength.extend(f['Wavelength_UVIR'])\n",
    "    spectra.extend(f['Spectra_UVIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dusty = np.array(mass_dusty)\n",
    "metals_dusty = np.array(metals_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f build_dust_history build_dust_history(1, directory_dusty, firstfile, lastfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "binwidth = 0.3\n",
    "rec_frac=0.43\n",
    "Hubble_h = 0.73\n",
    "\n",
    "#w = np.where((G_history[0].StellarMass > 0) & (G_history[0].MetalsStellarMass > 0))[0]\n",
    "#mass = np.log10(G_history[0].StellarMass[w] * 1.e10 / Hubble_h)\n",
    "\n",
    "w1 = np.where((G_history_dusty[0].StellarMass > 0.0)& (G_history_dusty[0].MetalsStellarMass > 0))[0]\n",
    "mass1 = np.log10(G_history_dusty[0].StellarMass[w1] * 1.e10 / Hubble_h)\n",
    "\n",
    "w2 = np.where((metals_dusty[:,63] > 0) & (mass_dusty[:,63] / Hubble_h > 0))[0]\n",
    "mass2 = np.log10(mass_dusty[:,63][w2] / Hubble_h)\n",
    "\n",
    "#w3 = np.where(Mass[:,63] > 0)[0]\n",
    "#mass3 = np.log10(Mass[:,63][w3])\n",
    "\n",
    "\n",
    "#w3 = np.where((metals_sage[:,63] > 0) & (mass_sage[:,63] / Hubble_h > 0))[0]\n",
    "#mass3 = np.log10(mass_sage[:,63][w3] / Hubble_h)\n",
    "\n",
    "#c_mass = np.log10(MassHist_old[0]*MetalHist_old[0] * (1. - rec_frac) / Hubble_h) #final computed mass #final computed mass\n",
    "\n",
    "mi = np.floor(min(mass1)) - 2\n",
    "ma = np.floor(max(mass1)) + 2\n",
    "ma = 14\n",
    "NB = int((ma - mi) / binwidth)\n",
    "\n",
    "#(counts, binedges) = np.histogram(mass, range=(mi, ma), bins=NB)\n",
    "(counts1, binedges1) = np.histogram(mass1, range=(mi, ma), bins=NB)\n",
    "(counts2, binedges2) = np.histogram(mass2, range=(mi, ma), bins=NB)\n",
    "#(counts3, binedges3) = np.histogram(mass3, range=(mi, ma), bins=NB)\n",
    "\n",
    "# Set the x-axis values to be the centre of the bins\n",
    "#xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "xaxeshisto2 = binedges2[:-1] + 0.5 * binwidth\n",
    "#xaxeshisto3 = binedges3[:-1] + 0.5 * binwidth\n",
    "\n",
    "#plt.plot(xaxeshisto, counts / (BoxSize/Hubble_h)**3 / binwidth, 'k-', label='sage')\n",
    "#plt.plot(xaxeshisto3, counts3 / (BoxSize/Hubble_h)**3 / binwidth, 'g:', label='mentari-tree')\n",
    "plt.plot(xaxeshisto1, counts1/ (BoxSize/Hubble_h)**3 / binwidth, 'r-', label='dusty-sage')\n",
    "plt.plot(xaxeshisto2, counts2/ (BoxSize/Hubble_h)**3 / binwidth, 'b:', label='mentari-dustysage')\n",
    "\n",
    "# Baldry+ 2008 modified data used for the MCMC fitting\n",
    "Baldry = np.array([\n",
    "            [7.05, 1.3531e-01, 6.0741e-02],\n",
    "            [7.15, 1.3474e-01, 6.0109e-02],\n",
    "            [7.25, 2.0971e-01, 7.7965e-02],\n",
    "            [7.35, 1.7161e-01, 3.1841e-02],\n",
    "            [7.45, 2.1648e-01, 5.7832e-02],\n",
    "            [7.55, 2.1645e-01, 3.9988e-02],\n",
    "            [7.65, 2.0837e-01, 4.8713e-02],\n",
    "            [7.75, 2.0402e-01, 7.0061e-02],\n",
    "            [7.85, 1.5536e-01, 3.9182e-02],\n",
    "            [7.95, 1.5232e-01, 2.6824e-02],\n",
    "            [8.05, 1.5067e-01, 4.8824e-02],\n",
    "            [8.15, 1.3032e-01, 2.1892e-02],\n",
    "            [8.25, 1.2545e-01, 3.5526e-02],\n",
    "            [8.35, 9.8472e-02, 2.7181e-02],\n",
    "            [8.45, 8.7194e-02, 2.8345e-02],\n",
    "            [8.55, 7.0758e-02, 2.0808e-02],\n",
    "            [8.65, 5.8190e-02, 1.3359e-02],\n",
    "            [8.75, 5.6057e-02, 1.3512e-02],\n",
    "            [8.85, 5.1380e-02, 1.2815e-02],\n",
    "            [8.95, 4.4206e-02, 9.6866e-03],\n",
    "            [9.05, 4.1149e-02, 1.0169e-02],\n",
    "            [9.15, 3.4959e-02, 6.7898e-03],\n",
    "            [9.25, 3.3111e-02, 8.3704e-03],\n",
    "            [9.35, 3.0138e-02, 4.7741e-03],\n",
    "            [9.45, 2.6692e-02, 5.5029e-03],\n",
    "            [9.55, 2.4656e-02, 4.4359e-03],\n",
    "            [9.65, 2.2885e-02, 3.7915e-03],\n",
    "            [9.75, 2.1849e-02, 3.9812e-03],\n",
    "            [9.85, 2.0383e-02, 3.2930e-03],\n",
    "            [9.95, 1.9929e-02, 2.9370e-03],\n",
    "            [10.05, 1.8865e-02, 2.4624e-03],\n",
    "            [10.15, 1.8136e-02, 2.5208e-03],\n",
    "            [10.25, 1.7657e-02, 2.4217e-03],\n",
    "            [10.35, 1.6616e-02, 2.2784e-03],\n",
    "            [10.45, 1.6114e-02, 2.1783e-03],\n",
    "            [10.55, 1.4366e-02, 1.8819e-03],\n",
    "            [10.65, 1.2588e-02, 1.8249e-03],\n",
    "            [10.75, 1.1372e-02, 1.4436e-03],\n",
    "            [10.85, 9.1213e-03, 1.5816e-03],\n",
    "            [10.95, 6.1125e-03, 9.6735e-04],\n",
    "            [11.05, 4.3923e-03, 9.6254e-04],\n",
    "            [11.15, 2.5463e-03, 5.0038e-04],\n",
    "            [11.25, 1.4298e-03, 4.2816e-04],\n",
    "            [11.35, 6.4867e-04, 1.6439e-04],\n",
    "            [11.45, 2.8294e-04, 9.9799e-05],\n",
    "            [11.55, 1.0617e-04, 4.9085e-05],\n",
    "            [11.65, 3.2702e-05, 2.4546e-05],\n",
    "            [11.75, 1.2571e-05, 1.2571e-05],\n",
    "            [11.85, 8.4589e-06, 8.4589e-06],\n",
    "            [11.95, 7.4764e-06, 7.4764e-06],\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "Baldry_xval = np.log10(10 ** Baldry[:, 0]  /Hubble_h/Hubble_h)\n",
    "Baldry_xval = Baldry_xval - 0.26  # convert back to Chabrier IMF\n",
    "\n",
    "Baldry_yvalU = (Baldry[:, 1]+Baldry[:, 2]) * Hubble_h*Hubble_h*Hubble_h\n",
    "Baldry_yvalL = (Baldry[:, 1]-Baldry[:, 2]) * Hubble_h*Hubble_h*Hubble_h\n",
    "\n",
    "plt.fill_between(Baldry_xval, Baldry_yvalU, Baldry_yvalL, facecolor='purple', alpha=0.25, label='Baldry et al. 2008 (z=0.1)')\n",
    "\n",
    "M_cole = np.array([9.06, 9.16, 9.26, 9.36, 9.46, 9.56, 9.66, 9.76, 9.86, 9.96, 10.06, 10.16, 10.26, 10.36, 10.46, 10.56, 10.66, 10.76, 10.86, 10.96, 11.06, 11.16, 11.26, 11.36, 11.46, 11.56, 11.66])\n",
    "Phi_cole = np.array([1.37e-2, 2.41e-2, 2.06e-2, 3.01e-2, 3.25e-2, 2.87e-2, 3.10e-2, 3.30e-2, 2.67e-2, 2.51e-2, 2.03e-2, 1.93e-2, 1.86e-2, 1.62e-2, 1.49e-2, 1.61e-2, 1.30e-2, 1.06e-2, 7.40e-3, 5.5e-3, 3.29e-3, 2.02e-3, 1.13e-3, 5.56e-4, 2.90e-4, 9.87e-5, 3.73e-5])\n",
    "Cole_xval = np.log10(10 ** M_cole / Hubble_h/Hubble_h)\n",
    "Cole_xval = Cole_xval - 0.26 #convert to Chabrier IMF\n",
    "\n",
    "Cole_yval = Phi_cole * Hubble_h*Hubble_h*Hubble_h\n",
    "plt.plot(Cole_xval, Cole_yval, '.', label='Cole et al. 2000')\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.axis([8.0, 13.0, 1.0e-6, 1.0e-1])\n",
    "\n",
    "# Set the x-axis minor ticks\n",
    "ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "\n",
    "plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{dex}^{-1})$')  # Set the y...\n",
    "plt.xlabel(r'$\\log_{10} M_{\\mathrm{stars}}\\ (M_{\\odot})$')  # and the x-axis labels\n",
    "\n",
    "leg = plt.legend(loc=0, numpoints=1, labelspacing=0.1)\n",
    "leg.draw_frame(False)  # Don't want a box frame\n",
    "for t in leg.get_texts():  # Reduce the size of the text\n",
    "    t.set_fontsize('medium')\n",
    "\n",
    "#plt.savefig('SMF_z0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute attenuation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = np.where((mass_dusty[:,snap_limit] > 0) & (dust[:,snap_limit] > 0))[0]\n",
    "w = np.where(mass_dusty[:,snap_limit] > 0)[0]\n",
    "Mass = mass_dusty[w] / Hubble_h \n",
    "Metals = metals_dusty[w]\n",
    "\n",
    "Dust = dust[w,snap_limit] / Hubble_h\n",
    "Gas = gas[w,snap_limit] / Hubble_h\n",
    "Rad = rad[w,snap_limit] / Hubble_h\n",
    "\n",
    "#Sigma_eta_ISM, eta_ISM[w] = compute_etaISM_Trayford(Dust, Gas, Rad)\n",
    "tau_BC, eta_BC, tau_ISM, eta_ISM = compute_attenuation_parameters (1, Dust, Gas, Rad)\n",
    "'''\n",
    "eta_BC = [-0.7] * len(Dust)\n",
    "eta_ISM_v2 = [-1.3] * len(Dust)\n",
    "Sigma_BC, tau_head_BC = compute_tauBC_Trayford(Dust, Gas, Rad)\n",
    "Sigma_tau_ISM, tau_head_ISM = compute_tauISM_Trayford(Dust, Gas, Rad)\n",
    "Sigma_eta_ISM, eta_ISM = compute_etaISM_Trayford(Dust, Gas, Rad)\n",
    "\n",
    "Sigma_ISM_v2, tau_ISM_v2 = compute_tauISM_Somerville (Dust, Rad)\n",
    "Sigma_BC_v2, tau_BC_v2 = compute_tauBC_Somerville (Dust, Rad)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where((mass_dusty[:,snap_limit] > 0))[0]\n",
    "Mass = mass_dusty[w] / Hubble_h \n",
    "Metals = metals_dusty[w]\n",
    "\n",
    "DustMass = dust[w,snap_limit] / Hubble_h\n",
    "GasMass = gas[w,snap_limit] / Hubble_h\n",
    "Radius = rad[w,snap_limit] / Hubble_h\n",
    "\n",
    "eta_BC = [-0.7] * len(DustMass)\n",
    "eta_ISM = [-1.3] * len(DustMass)\n",
    "tau_BC = np.zeros(len(DustMass))\n",
    "tau_ISM = np.zeros(len(DustMass))\n",
    "\n",
    "w = np.where(DustMass > 0)[0]\n",
    "print(w)\n",
    "'''\n",
    "if prescription_choice == 0:\n",
    "    Sigma_BC, tau_BC[w] = compute_tauBC_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "    Sigma_tau_ISM, tau_ISM[w] = compute_tauISM_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "    Sigma_eta_ISM, eta_ISM[w] = compute_etaISM_Trayford(DustMass[w], GasMass[w], Radius[w])\n",
    "\n",
    "elif prescription_choice == 1:\n",
    "'''\n",
    "Sigma_ISM, tau_ISM[w] = compute_tauISM_Somerville (DustMass[w], Radius[w])\n",
    "Sigma_BC, tau_BC[w] = compute_tauBC_Somerville (DustMass[w], Radius[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from Trayford+ 19\n",
    "#Sigma_dust vs tau ISM\n",
    "Sigma_dust_tau = [4.088, 4.351, 4.579, 4.823, 5.057, 5.292, 5.528, 5.765, 6.001, 6.234, 6.470, 6.704, 6.941, 7.177, 7.416]\n",
    "tau_head_Trayford = [0.031, 0.059, 0.078, 0.129, 0.203, 0.308, 0.467, 0.647, 0.838, 1.065, 1.235, 1.475, 1.571, 1.645, 1.806]\n",
    "\n",
    "Sigma_dust_eta = [4.116, 4.354, 4.588, 4.822, 5.061, 5.293, 5.533, 5.763, 6.003, 6.236, 6.469, 6.706, 6.943, 7.181, 7.411]\n",
    "eta_ISM_Trayford = [-1.379, -1.357, -1.334, -1.243, -1.170, -1.062, -0.922, -0.778, -0.668, -0.570, -0.506, -0.453, -0.381, -0.318, -0.307]\n",
    "\n",
    "plt.plot(Sigma_dust_tau, tau_head_Trayford, '-', label=r'Trayford+ 19 ($\\tau_\\mathrm{ISM}$)')\n",
    "plt.plot(Sigma_tau_ISM, tau_head_ISM, '.', markersize=6, label=r'$\\tau_\\mathrm{ISM}\\ (r = 0.4 r_s)$')\n",
    "plt.plot(Sigma_BC, tau_head_BC, '.', markersize=1, label=r'$\\tau_\\mathrm{BC}\\ (r = 0.4 r_s)$')\n",
    "\n",
    "plt.plot(np.log10(Sigma_ISM_v2 * 1e6), tau_ISM_v2, '.', markersize=1, label=r'Somerville formula ($\\tau_\\mathrm{ISM}$)')\n",
    "plt.plot(np.log10(Sigma_BC_v2 * 1e6), tau_BC_v2, '.', markersize=1, label=r'Somerville formula ($\\tau_\\mathrm{BC}$)')\n",
    "plt.xlim(2, 8)\n",
    "plt.ylim(0, 3)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$\\log_{10} \\Sigma_\\mathrm{dust} (\\mathrm{M_\\odot} \\mathrm{kpc}^{-2})$')\n",
    "plt.ylabel(r'$\\tau$')\n",
    "#plt.savefig('plots/tau_mini_somerville.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Sigma_dust_tau, eta_ISM_Trayford, '.-', label='Trayford+ 19 ($\\eta_\\mathrm{ISM}$)')\n",
    "plt.plot(Sigma_eta_ISM, eta_ISM, '.', label=r'$\\eta_\\mathrm{ISM}\\ (r = 0.4 r_s)$')\n",
    "\n",
    "plt.axhline(-0.7, c='green', lw=0.8, label=r'$\\eta_\\mathrm{BC}$')\n",
    "plt.xlabel(r'$\\log_{10} \\Sigma_\\mathrm{dust} (\\mathrm{M_\\odot} \\mathrm{kpc}^{-2})$')\n",
    "plt.ylabel(r'$\\eta$')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.xlim(2, 8)\n",
    "#plt.savefig('plots/eta_03.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate spectra (including attenuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = np.asarray([0.0124, 0.0246, 0.0491, 0.1037, 0.1871, 0.2120, 0.2399, 0.2709, 0.3054, 0.3438, 0.3864, 0.4335, 0.4856, 0.5430, 0.6062, 0.6756, 0.7517, 0.8349, 0.9259, 1.0249, 1.1327, 1.2496, 1.3763, 1.5131, 1.6606, 1.8192, 1.9895, 2.1717, 2.3662, 2.5734, 2.7934, 3.0265, 3.2726, 3.5318, 3.8038, 4.0886, 4.3856, 4.6944, 5.0144, 5.3488, 5.6849, 6.0337, 6.3901, 6.7531, 7.1215, 7.4940, 7.8694, 8.2464, 8.6238, 9.0004, 9.3750, 9.7463, 10.1133, 10.4750, 10.8303, 11.1783, 11.5181, 11.8490, 12.1702, 12.4811, 12.7810, 13.0695, 13.3459, 13.6098])\n",
    "lookbacktime = sorted((np.array([13.6098]*len(Age)) - Age) * 1.e9)\n",
    "time_BC = 10**7\n",
    "#tau_head_ISM = 0.65\n",
    "#tau_head_ISM_2 = 0.5\n",
    "#tau_head_BC = 1.0\n",
    "#eta_BC = -0.7\n",
    "#eta_BC = [-0.7, -0.7]\n",
    "#eta_BC_2 = -1.3\n",
    "#eta_ISM = -1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_s, spectra_s, spectra_dusty_s = generate_SED(1, Age, Mass, Metals, \n",
    "             tau_BC_v2, tau_ISM_v2, eta_BC, eta_ISM_v2, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra, spectra_dusty = generate_SED(1, Age, Mass, Metals, \n",
    "             tau_BC, tau_ISM, eta_BC, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dale_template = np.loadtxt('files/spectra.0.00AGN.dat', unpack=True)\n",
    "lambda_IR = Dale_template[0] * 1e4 #convert from micron to Angstrom\n",
    "\n",
    "Ldust = (spectra - spectra_dusty)\n",
    "w = np.where(wavelength < 912)[0]\n",
    "idx_912 = w[-1]\n",
    "\n",
    "all_wave = np.unique(np.concatenate((wavelength, lambda_IR)))\n",
    "all_wave.sort(kind='mergesort')\n",
    "UVIR = np.zeros((len(Ldust), len(all_wave)))\n",
    "\n",
    "for i in range(len(Ldust)):\n",
    "    LIR_mentari = trapz(Ldust[i][idx_912:-1], wavelength[idx_912:-1])\n",
    "\n",
    "    idx = determine_idx_Marcillac(LIR_mentari)\n",
    "    spectra_IR = 10 ** Dale_template[idx[0]+1]\n",
    "\n",
    "    LIR_dale = trapz(spectra_IR, lambda_IR)\n",
    "    scaling = LIR_mentari / LIR_dale\n",
    "    spectra_IR_dale = spectra_IR * scaling \n",
    "\n",
    "    wa = np.where((all_wave < wavelength[-1]) | (all_wave == wavelength[-1]))[0]\n",
    "    UVIR[i][wa] += np.interp(all_wave[wa], wavelength, spectra_dusty[i])\n",
    "\n",
    "    we = np.where((all_wave > lambda_IR[0]) | (all_wave == lambda_IR[0]))[0]\n",
    "    UVIR[i][we] += np.interp(all_wave[we], lambda_IR, spectra_IR_dale)\n",
    "\n",
    "plt.plot(all_wave, UVIR[i])\n",
    "plt.plot(wavelength, spectra_dusty[i])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_cf, spectra_cf, spectra_dusty_cf = generate_SED(1, Age, Mass, Metals, \n",
    "             tau_head_BC, tau_head_ISM, eta_BC, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f generate_SED generate_SED(1, Age, Mass, Metals, tau_head_BC, tau_head_ISM, eta_BC, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing H-alpha luminosity (Orsi+ 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(wavelength < 912)[0]\n",
    "idx_912 = w[-1]\n",
    "delta = wavelength[1:idx_912] - wavelength[0:idx_912-1]\n",
    "\n",
    "Lsun2cgs = 3.846e33\n",
    "h = 6.6261e-27 #cgs\n",
    "c = 2.99e10 #cgs\n",
    "L_Ha = []\n",
    "\n",
    "for i in range(len(spectra_dusty)):\n",
    "    int_Q = sum(wavelength[1:idx_912] * spectra_dusty[i][1:idx_912] * delta)\n",
    "    Q = int_Q * Lsun2cgs / (h*c)\n",
    "    L_ha = 1.37e-12 * Q\n",
    "    L_Ha.append(np.log10(L_ha / Hubble_h / Hubble_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = 40\n",
    "ma = 50\n",
    "binwidth = 0.3\n",
    "NB = int((ma - mi) / binwidth)\n",
    "volume = (BoxSize/Hubble_h)**3\n",
    "\n",
    "plt.figure()\n",
    "ax =plt.subplot(111)\n",
    "\n",
    "counts, binedges = np.histogram(L_Ha, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, lw=1.0)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Dale+ 2014 IR template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_dale, spectra_dale = add_IR_Dale(wavelength, spectra, spectra_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_s, spectra_s = combine_Dale_SUNRISE(Dust, wavelength, spectra, spectra_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Dust), len(spectra_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random checking for IR spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where((Mass[:,63] / Hubble_h > 5.65e10) & (Mass[:,63] / Hubble_h < 6e10) & (Dust > 0))[0]\n",
    "a=w[6]\n",
    "alpha_SF, log_fnu_SF = np.loadtxt('files/alpha.dat', unpack=True)\n",
    "Dale_template = np.loadtxt('files/spectra.0.00AGN.dat', unpack=True)\n",
    "lambda_IR = Dale_template[0] * 1e4 #convert from micron to Angstrom\n",
    "\n",
    "Ldust = (spectra - spectra_dusty)\n",
    "w = np.where(wavelength < 912)[0]\n",
    "idx_912 = w[-1]\n",
    "\n",
    "all_wave = np.unique(np.concatenate((wavelength, lambda_IR)))\n",
    "all_wave.sort(kind='mergesort')\n",
    "UVIR = np.zeros((len(Ldust), len(all_wave)))\n",
    "\n",
    "LIR_mentari = trapz(Ldust[a][idx_912:-1], wavelength[idx_912:-1])\n",
    "\n",
    "log_fnu = 0.128 * np.log10(LIR_mentari) - 1.611\n",
    "delta_fnu = abs(log_fnu_SF - log_fnu)\n",
    "idx = np.where(delta_fnu==min(delta_fnu))[0]\n",
    "spectra_IR = 10 ** Dale_template[idx[0]+1]\n",
    "LIR_dale = trapz(spectra_IR, lambda_IR)\n",
    "scaling = LIR_mentari / LIR_dale\n",
    "spectra_IR_dale = spectra_IR * scaling \n",
    "\n",
    "new_spectra = np.interp(all_wave, wavelength, spectra_dusty[a])\n",
    "w = np.where(all_wave > lambda_IR[0])[0]\n",
    "new_IR = np.interp(all_wave[w], lambda_IR, spectra_IR_dale)\n",
    "new_spectra[w] = new_spectra[w] + new_IR\n",
    "\n",
    "lam, sed = find_template_SUNRISE(np.log10(LIR_mentari), np.log10(Dust[a]))\n",
    "w = np.where(all_wave < lam[0]*1e4)\n",
    "all_wave_b = np.unique(np.concatenate((all_wave[w], lam*1e4)))\n",
    "all_wave_b.sort(kind='mergesort')\n",
    "print(min(lam*1e4), max(lam*1e4))\n",
    "\n",
    "new_spectra_b = np.zeros(len(all_wave_b))\n",
    "w = np.where((all_wave_b < lam[0]*1e4) | (all_wave_b == lam[0]*1e4))\n",
    "new_spectra_b[w] = np.interp(all_wave_b[w], all_wave, new_spectra*all_wave)\n",
    "'''\n",
    "new_spectra_b = np.interp(all_wave_b, wavelength, spectra_dusty[a]*wavelength)\n",
    "w = np.where(((all_wave_b < lam[0]*1e4) | (all_wave_b == lam[0]*1e4)) & (all_wave_b > lambda_IR[0]))[0]\n",
    "MIR_b = np.interp(all_wave_b[w], lambda_IR, spectra_IR_dale*lambda_IR)\n",
    "new_spectra_b[w] = new_spectra_b[w] + MIR_b\n",
    "'''\n",
    "w = np.where(all_wave_b > lam[0]*1e4)[0]\n",
    "#new_IR_b = np.interp(all_wave_b[w], lam*1e4, sed)\n",
    "#new_spectra_b[w] = new_spectra_b[w] + new_IR_b \n",
    "new_spectra_b[w] = np.interp(all_wave_b[w], lam*1e4, sed)\n",
    "\n",
    "plt.plot(all_wave_b, new_spectra_b, label=\"Safarzadeh+15\")\n",
    "plt.plot(all_wave, new_spectra*all_wave, label='Dale+14')\n",
    "#plt.plot(all_wave, all_spec*all_wave)\n",
    "#plt.plot(all_wave_b, all_spec_b)\n",
    "plt.plot(wave, spec, lw=0.5, label= ('NGC 5055 (Brown et al. 2014)'))\n",
    "\n",
    "plt.ylim(1e7, 1e11)\n",
    "plt.xlim(1200, 1e7)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "\n",
    "plt.xlabel(r'$\\lambda\\ (\\AA) $')\n",
    "plt.ylabel(r'log $\\lambda L_{\\lambda} (L_{\\odot})$')\n",
    "\n",
    "plt.savefig('SED-UVIR.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_spectra_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_IR, LIR[2] * lambda_IR)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_IR_v2 = 10 ** spectra_IR\n",
    "\n",
    "\n",
    "print(LIR[0]/L_TIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(Dust), np.log10(LIR), '.')\n",
    "plt.xlim(4, 9)\n",
    "plt.ylim(5, 15)\n",
    "plt.xlabel(r'log $M_\\mathrm{dust} (M_{\\odot})$')\n",
    "plt.ylabel(r'log $\\lambda L_{IR} (L_{\\odot})$')\n",
    "#plt.savefig('plots/LIR-Mdust.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(Dust), alpha, '.')\n",
    "plt.xlim(4, 9)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel(r'log $M_\\mathrm{dust} (M_{\\odot})$')\n",
    "plt.ylabel(r'$ \\alpha_\\mathrm{SF}$')\n",
    "plt.savefig('plots/alpha-Mdust.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(LIR), alpha_list, '.')\n",
    "plt.xlabel(r'log $\\lambda L_{IR} (L_{\\odot})$')\n",
    "\n",
    "plt.axhline(1.5)\n",
    "plt.axvline(11.6)\n",
    "plt.axvline(9.5)\n",
    "plt.axhline(3.05)\n",
    "\n",
    "#plt.xlim(4, 9)\n",
    "#plt.ylim(1, 8)\n",
    "#plt.xlabel(r'log $M_\\mathrm{dust} (M_{\\odot})$')\n",
    "#plt.ylabel(r'$ \\alpha_\\mathrm{SF}$')\n",
    "#plt.savefig('plots/alpha-Mdust.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting full spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hubble_h = 0.73\n",
    "print(len(Mass[0]))\n",
    "w = np.where(Mass[:,63] == max(Mass[:,63]))[0]\n",
    "MassHist = list(Mass[w])\n",
    "#MetalHist = list(metals_dusty[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To plot the spectra:\n",
    "\n",
    "ax = plt.subplot2grid((1,1), (0,0))\n",
    "#divider = make_axes_locatable(ax)\n",
    "#ax.plot(wavelength, np.log10(Spectra_arr[10] * np.array(wavelength)), lw=0.5, label='stellar')\n",
    "#ax.plot(wavelength, np.log10(spectra_dusty[10] * np.array(wavelength)), lw=0.5, label='dusty')\n",
    "#ax.plot(np.array(wavelength_old), spectra_old[0] * np.array(wavelength_old), lw=0.5, label='sage')\n",
    "#plt.plot(lambda_IR, np.log10(LIR[10] * lambda_IR))\n",
    "#plt.plot(all_wave, np.log10(UVIR[10] * all_wave))\n",
    "plt.plot(full_wavelength, np.log10(Spectra_arr[1] * full_wavelength), '--')\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda\\ (\\AA) $')\n",
    "ax.set_ylabel(r'log $\\lambda L_{\\lambda} (L_{\\odot})$')\n",
    "ax.set_xscale('log')\n",
    "#ax.set_yscale('log')\n",
    "#plt.savefig('SED-dusty.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral = np.loadtxt('NGC_5055_spec.dat', unpack=True)\n",
    "wave = spiral[0]\n",
    "spec = spiral[1]\n",
    "dl = 7.8 * 3.086e+24 #Mpc to cm\n",
    "spec = spec*wave * (4*np.pi*dl**2) / 3.826e33 #ergs/s to Lsun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellarmass = G_history_dusty[0].StellarMass * 1e10 / Hubble_h\n",
    "dustmass = G_history_dusty[0].ColdDust * 1e10 / Hubble_h\n",
    "sfr = G_history_dusty[0].SfrDisk + G_history_dusty[0].SfrBulge\n",
    "\n",
    "w = np.where((stellarmass > 5.65e10) & (stellarmass < 6e10) & (dustmass > 0))[0]\n",
    "print(len(w), stellarmass[w[3]], dustmass[w[3]], sfr[w[3]])\n",
    "\n",
    "w = np.where((Mass[:,63] / Hubble_h > 5.65e10) & (Mass[:,63] / Hubble_h < 6e10) & (Dust > 0))[0]\n",
    "print(len(w), Mass[w[6],63] / Hubble_h, Dust[w[6]])\n",
    "#To plot the spectra:\n",
    "ax = plt.subplot2grid((1,1), (0,0))\n",
    "#divider = make_axes_locatable(ax)\n",
    "plt.plot(wave, spec, lw=1, label= ('NGC 5055 (Brown et al. 2014)'))\n",
    "#ax.plot(np.array(wavelength), spectra[w[6]] * np.array(wavelength), lw=2, label='intrinsic')\n",
    "#ax.plot(np.array(wavelength), spectra_dusty[w[1]] * np.array(wavelength), lw=0.5, label='dusty')\n",
    "#ax.plot(np.array(all_wave), UVIR[w[6]] * all_wave,  lw=0.5, label='dusty')\n",
    "ax.plot(np.array(full_wavelength), Spectra_arr[w[6]] * full_wavelength, '--', lw=0.5, label='attenuated')\n",
    "\n",
    "#ax.plot(np.array(wavelength_sage), spectra_sage[0] * np.array(wavelength_sage), lw=0.5, label='sage')\n",
    "#ax.plot(np.array(wavelength_old), spectra_old[0] * np.array(wavelength_old), lw=0.5, label='sage')\n",
    "plt.ylim(1e7, 1e11)\n",
    "plt.xlim(1200, 1e7)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda\\ (\\AA) $')\n",
    "ax.set_ylabel(r'log $\\lambda L_{\\lambda} (L_{\\odot})$')\n",
    "\n",
    "#plt.savefig('SED-spiral.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('mentari_test7.h5', 'a') as f:\n",
    "    full_wavelength_a = np.array(f[\"Wavelength_UVIR\"])\n",
    "    full_spectra_a = np.array(f['Spectra_UVIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_spectra_a), len(full_spectra_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting UV - optical LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = ('TwoMass_Ks', 'Sdss_u', 'Sdss_g', 'Sdss_r', 'Sdss_i', 'Sdss_z')\n",
    "z = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty = compute_mab(wavelength_dale, spectra_dale, filter_list, z)\n",
    "mab_dusty_s = compute_mab(wavelength_s, spectra_s, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f compute_mab compute_mab(full_wavelength, full_spectra, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_t = compute_mab(wavelength, spectra_dusty, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_nodust = compute_mab(wavelength, spectra, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_s = compute_mab(wavelength_s, spectra_dusty_s, filter_list, z)\n",
    "mab_dusty_cf = compute_mab(wavelength_cf, spectra_dusty_cf, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubble=0.73\n",
    "label = ['Mu', 'Mg', 'Mr', 'Mi', 'Mz']\n",
    "color = ('grey', 'black', 'blue', 'red', 'green', 'purple')\n",
    "volume = (BoxSize/Hubble_h)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = -30.0\n",
    "ma = -15.0\n",
    "binwidth = 0.3\n",
    "NB = int((ma - mi) / binwidth)\n",
    "#M = np.arange(mi, ma, 0.01)\n",
    "\n",
    "plt.figure()\n",
    "ax =plt.subplot(111)\n",
    "\n",
    "# Cole et al. 2001 K band 2dFGRS LF\n",
    "Cole_Phi = np.array([3.1315561E-03, 8.2625253E-03, 0.0000000E+00, 4.6483092E-03, 5.7576019E-03, 9.1649834E-03, 1.1232893E-02,\n",
    "            1.0536440E-02, 8.5763102E-03, 8.8181989E-03, 6.9448259E-03, 6.0896124E-03, 9.2596142E-03, 6.9631678E-03,\n",
    "            7.2867479E-03, 6.9923755E-03, 5.9844730E-03, 5.9305103E-03, 5.3865365E-03, 5.8525647E-03, 5.2373926E-03,\n",
    "            4.9635037E-03, 4.1801766E-03, 2.7171015E-03, 1.8800517E-03, 1.2136410E-03, 6.5419916E-04, 3.4594961E-04,\n",
    "            1.4771589E-04, 5.5521199E-05, 2.1283222E-05, 9.4211919E-06, 1.0871951E-06, 2.7923562E-07])\n",
    "Cole_PhiErr = np.array([3.6377162E-03, 6.6833422E-03, 1.0000000E-10, 4.0996978E-03, 4.3155681E-03, 5.6722397E-03, 6.4211683E-03,\n",
    "            5.7120644E-03, 4.6346937E-03, 3.8633577E-03, 2.4383855E-03, 1.6279118E-03, 1.6941463E-03, 1.1781409E-03,\n",
    "            9.7785855E-04, 7.9027453E-04, 6.0649612E-04, 5.1598746E-04, 4.2267537E-04, 3.7395130E-04, 2.8177485E-04,\n",
    "            2.1805518E-04, 1.6829016E-04, 1.1366483E-04, 8.1871600E-05, 5.7472309E-05, 3.6554517E-05, 2.3141622E-05,\n",
    "            1.2801432E-05, 6.5092854E-06, 3.3540452E-06, 1.9559407E-06, 5.6035748E-07, 2.8150106E-07])\n",
    "Cole_Mag = np.array([-18.00000, -18.25000, -18.50000, -18.75000, -19.00000, -19.25000, -19.50000, -19.75000, -20.00000,\n",
    "            -20.25000, -20.50000, -20.75000, -21.00000, -21.25000, -21.50000, -21.75000, -22.00000, -22.25000,\n",
    "            -22.50000, -22.75000, -23.00000, -23.25000, -23.50000, -23.75000, -24.00000, -24.25000, -24.50000,\n",
    "            -24.75000, -25.00000, -25.25000, -25.50000, -25.75000, -26.00000, -26.25000])\n",
    "\n",
    "# Huang et al. 2003 K band Hawaii+AAO LF\n",
    "Huang_Phi = np.array([0.0347093, 0.0252148, 0.0437980, 0.0250516, 0.00939655, 0.0193473, 0.0162743, 0.0142267, 0.0174460,\n",
    "            0.0100971, 0.0136507, 0.00994688, 0.00655286, 0.00528234, 0.00310017, 0.00157789, 0.000721131,\n",
    "            0.000272634, 8.33409e-05, 2.12150e-05, 3.97432e-06, 5.07697e-06, 5.42939e-07])\n",
    "Huang_PhiErr = np.array([ 0.0249755, 0.0181685, 0.0161526, 0.0105895, 0.00479689, 0.00525068, 0.00428192, 0.00308970, 0.00248676,\n",
    "            0.00166458, 0.00166691, 0.00106289, 0.000704721, 0.000527429, 0.000340814, 0.000170548, 8.25681e-05,\n",
    "            3.81529e-05, 1.50279e-05, 6.16614e-06, 2.34362e-06, 1.98971e-06, 5.54946e-07])\n",
    "Huang_Mag = np.array([-19.8000, -20.1000, -20.4000, -20.7000, -21.0000, -21.3000, -21.6000, -21.9000, -22.2000, -22.5000,\n",
    "            -22.8000, -23.1000, -23.4000, -23.7000, -24.0000, -24.3000, -24.6000, -24.9000, -25.2000,\n",
    "            -25.5000, -25.8000, -26.1000, -26.4000])\n",
    "\n",
    "# Finally plot the observational data\n",
    "Cole_xval = Cole_Mag + 0.65 #convert to Chabrier IMF\n",
    "Huang_xval = Huang_Mag + 0.65 #convert to Chabrier IMF\n",
    "plt.errorbar(Cole_xval+5.0*np.log10(Hubble_h), Cole_Phi*Hubble_h*Hubble_h*Hubble_h, yerr=Cole_PhiErr*Hubble_h*Hubble_h*Hubble_h, color='m', lw=1.0, marker='o', ls='none', label='Cole et al. 2001')\n",
    "plt.errorbar(Huang_xval+5.0*np.log10(Hubble_h), Huang_Phi*Hubble_h*Hubble_h*Hubble_h, yerr=Huang_PhiErr*Hubble_h*Hubble_h*Hubble_h, color='g', lw=1.0, marker='o', ls='none', label='Huang et al. 2003')\n",
    "\n",
    "twomass_k = [0]\n",
    "sdss_ug = [1, 2]\n",
    "sdss_r = [3]\n",
    "sdss_i = [4]\n",
    "sdss_z = [5]\n",
    "sdss_iz=[4, 5]\n",
    "sdss =[1,2,3,4,5]\n",
    "'''\n",
    "counts, binedges = np.histogram(mab_nodust[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, c=color[0], lw=1.0, label='no-dust')\n",
    "'''\n",
    "counts, binedges = np.histogram(mab_dusty[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, '--', c=color[0], lw=1.0, label='Trayford+ 19')\n",
    "\n",
    "counts, binedges = np.histogram(mab_dusty_s[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, '-.', c='b', lw=1.0, label='Somerville+ 12')\n",
    "'''\n",
    "counts, binedges = np.histogram(mab_dusty_cf[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, ':', c='r', lw=1.0, label='CF00')\n",
    "\n",
    "counts, binedges = np.histogram(mab_dusty_4[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, ':', c='r', lw=1.0, label=r'$\\eta_\\mathrm{BC}=-1.3$')\n",
    "\n",
    "counts, binedges = np.histogram(mab_dusty_5[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, '-.', c='b', lw=1.0, label=r'$\\eta_\\mathrm{ISM}=-1.3$')\n",
    "\n",
    "\n",
    "counts, binedges = np.histogram(mab_sage[0]-1.85, range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ volume / binwidth, '--', c=color[0], lw=2.0, label='sage-no-dust')\n",
    "'''\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{mag}^{-1})$')  # Set the y...\n",
    "plt.xlabel(r'$M_\\mathrm{K}$')\n",
    "plt.ylim(4e-7, 4e-2)\n",
    "plt.xlim(-19.5, -27.5)\n",
    "ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "leg = plt.legend(loc=0, numpoints=1, labelspacing=0.1)\n",
    "leg.draw_frame(False)  # Don't want a box frame\n",
    "for t in leg.get_texts():  # Reduce the size of the text\n",
    "    t.set_fontsize('medium')\n",
    "#plt.savefig('plots/k-mini.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = -30.0\n",
    "ma = -15.0\n",
    "binwidth = 0.3\n",
    "NB = int((ma - mi) / binwidth)\n",
    "M = np.arange(mi, ma, 0.1)\n",
    "label = ['Mk', 'Mu', 'Mg', 'Mr', 'Mi', 'Mz']\n",
    "# Observations from Kelvin et al. 2013\n",
    "Mstar = [0, -18.53, -20.28, -20.90, -21.45, -21.78]\n",
    "alpha1 = [0, -0.91, -1.29, -1.13, -1.35, -1.46]\n",
    "phistar1 = [0, 0.00964, 0.00351, 0.00451, 0.00220, 0.0014]\n",
    "alpha2 = [0, 1.25, 0.06, 0.53, -0.09, -0.26]\n",
    "phistar2 = [0, 0.00146, 0.00488, 0.00301, 0.00487, 0.00505]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "row = 2\n",
    "col = 3\n",
    "for i in range(1, 6):\n",
    "    ax =plt.subplot(row, col, i)\n",
    "    '''\n",
    "    counts, binedges = np.histogram(mab_nodust[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto, counts/ volume / binwidth, c=color[i], lw=1.0, label='no-dust')\n",
    "    '''\n",
    "    counts, binedges = np.histogram(mab_dusty[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto, counts/ volume / binwidth, '--', c=color[i], lw=1.0, label='Trayford+ 19')\n",
    "    \n",
    "    counts, binedges = np.histogram(mab_dusty_s[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto, counts/ volume / binwidth, '-.', c=color[i], lw=1.0, label='Somerville+ 12')\n",
    "    '''\n",
    "    counts, binedges = np.histogram(mab_dusty_cf[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto, counts/ volume / binwidth, ':', c=color[i],lw=1.0, label='CF00')\n",
    "    '''\n",
    "    #plot Kelvin+ 13 dataset\n",
    "    M_plot = M + 0.65 #convert back to Chabrier IMF\n",
    "    xval = 10.0 ** (0.4*(Mstar[i]-M)) \n",
    "    yval = 0.4 * np.log(10.0) * (phistar1[i] * xval ** (alpha1[i]+1) + phistar2[i] * xval ** (alpha2[i]+1)) * np.exp(-xval)                \n",
    "    plt.plot(M_plot, yval, '--', c=color[i], lw=0.5, label='Kelvin+ 13')\n",
    "\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.ylim(2e-7, 2e-2)\n",
    "    plt.xlim(-17.1, -24.9)\n",
    "    ax.tick_params(axis='both', which='both', direction='in')\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{dex}^{-1})$')  # Set the y...\n",
    "    plt.xlabel(label[i])\n",
    "\n",
    "\n",
    "leg = plt.legend(loc=0, numpoints=1, labelspacing=0.1)\n",
    "leg.draw_frame(False)  # Don't want a box frame\n",
    "for t in leg.get_texts():  # Reduce the size of the text\n",
    "    t.set_fontsize('medium')\n",
    "#plt.savefig('plots/sdss-mini.png')\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting IR LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_filter = ('IRAC_1','IRAC_4', 'MIPS_24um', 'MIPS_70um','PACS_160um', 'SPIRE_250um', 'SPIRE_500um')\n",
    "z=0\n",
    "mab_IR = compute_mab(wavelength_dale, spectra_dale, IR_filter, z)\n",
    "mab_IR_s = compute_mab(wavelength_s, spectra_s, IR_filter, z)\n",
    "#mab_IR_s = compute_mab(full_wavelength_s, full_spectra_s, IR_filter, z)\n",
    "#mab_IR_cf = compute_mab(full_wavelength_cf, full_spectra_cf, IR_filter, z)\n",
    "#mab_IR = compute_mab(all_wave, UVIR, IR_filter, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(Dust > 1e6)[0]\n",
    "dusty = Dust[w]\n",
    "w = np.where(mab_IR[3] > -22)[0]\n",
    "print(max(dusty[w]), max(dusty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_filter_d = ('MIPS_70um','PACS_160um', 'SPIRE_250um', 'SPIRE_500um')\n",
    "z=0\n",
    "mab_IR = compute_mab(wavelength_dale, spectra_dale, IR_filter_d, z)\n",
    "mab_IR_s = compute_mab(wavelength_s, spectra_s, IR_filter_d, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(full_wavelength), full_spectra[w[6]] * full_wavelength,  lw=0.5, label='dusty')\n",
    "plt.ylim(1e8, 1e11)\n",
    "plt.xlim(1200, 1e7)\n",
    "\n",
    "F = read_filters()\n",
    "for i in range(len(IR_filter)):\n",
    "    filters_wave = eval('F.' + IR_filter[i] + '_wave')\n",
    "    filters = eval('F.' + IR_filter[i])\n",
    "    plt.plot(filters_wave, filters*2e10, label=IR_filter[i])\n",
    "\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.xlabel(r'$\\lambda\\ (\\AA) $')\n",
    "plt.ylabel(r'log $\\lambda L_{\\lambda} (L_{\\odot})$')\n",
    "#plt.savefig('plots/IRfilters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowlim_list = [-25.3, -25.3, -23.8]\n",
    "uplim_list = [-29, -29, -28]\n",
    "\n",
    "row = 4\n",
    "col = 2\n",
    "fig, axes = plt.subplots(row, col, sharey=True, figsize=(9,12))\n",
    "\n",
    "mi = -30.0\n",
    "ma = -20.0\n",
    "binwidth = 0.5\n",
    "NB = int((ma - mi) / binwidth)\n",
    "\n",
    "for i in range(0, 7):\n",
    "    ax = plt.subplot(row, col, i+1)\n",
    "    counts1, binedges1 = np.histogram(mab_IR[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, '--', lw=1.5, label=IR_filter[i] + 'Trayford+09')\n",
    "    \n",
    "    counts1, binedges1 = np.histogram(mab_IR_s[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, '-.', lw=1.5, label='Somerville+ 12')\n",
    "    '''\n",
    "    counts1, binedges1 = np.histogram(mab_IR_cf[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, ':', lw=1.5, label='CF00')\n",
    "    '''\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.ylim(2e-5, 2e-2)\n",
    "    plt.xlim(-30.5, -20.5)\n",
    "    ax.tick_params(axis='both', which='both', direction='in')\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{dex}^{-1})$')  # Set the y...\n",
    "    \n",
    "\n",
    "plt.subplot(421)\n",
    "Dai_mag = [-21.852, -21.591, -21.348, -21.087, -20.850, -20.619, -20.351, -20.157,\n",
    "          -19.886, -19.596, -19.347, -19.090, -18.855, -18.602, -18.364, -18.114,\n",
    "          -17.854, -17.598, -17.351, -17.127, -16.833, -16.600, -16.344, -16.101, \n",
    "          -15.862, -15.566]\n",
    "Dai_phi = 10 ** np.array([-3.527, -3.028, -2.935, -2.674, -2.548, -2.389, -2.300, -2.197, -2.148, -2.046,\n",
    "          -2.032, -1.974, -1.944, -1.957, -1.718, -1.832, -1.766, -1.825, -1.830, -1.469,\n",
    "          -1.198, -1.408, -1.574, -1.701, -1.020, -1.027])\n",
    "plt.errorbar(Dai_mag+5.0*np.log10(Hubble_h), Dai_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Dai et al. 2009')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(-26.5, -16.5)\n",
    "\n",
    "plt.subplot(422).set_yticklabels([])\n",
    "plt.subplot(422).set_ylabel('')\n",
    "Dai_mag = [-23.768, -23.495, -23.266, -22.995, -22.734, -22.466, -22.265, -21.976,\n",
    "          -21.790, -21.519, -21.264, -20.966, -20.752, -20.479, -20.274, -19.986,\n",
    "          -19.718, -19.493, -19.220, -18.996, -18.749, -18.491, -18.247, -18.002,\n",
    "          -17.745, -17.491, -17.265, -16.762, -16.013, -16.985]\n",
    "Dai_phi = 10 ** np.array([-4.235, -3.838, -3.500, -3.339, -3.038, -2.803, -2.712,\n",
    "                         -2.598, -2.523, -2.448, -2.388, -2.300, -2.253, -2.237,\n",
    "                          -2.084, -2.092, -2.068, -1.921, -2.007, -1.799, -1.784,\n",
    "                         -1.767, -1.686, -1.422, -1.371, -1.596, -1.120, -1.203,\n",
    "                         -1.566, -1.863])\n",
    "plt.errorbar(Dai_mag+5.0*np.log10(Hubble_h), Dai_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Dai et al. 2009')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(-26.5, -16.5)\n",
    "\n",
    "plt.subplot(423)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(-26.5, -20.5)\n",
    "\n",
    "plt.subplot(424).set_yticklabels([])\n",
    "plt.subplot(424).set_ylabel('')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(425)\n",
    "#Marchetti_mag, Marchetti_phi = np.loadtxt('files/Marchetti_PACS160.dat', usecols=(0,1), unpack=True)\n",
    "Marchetti_mag = [-27.811, -27.373, -26.953, -26.573, -26.031, -25.686, -25.271, -24.844,\n",
    "                -24.413, -23.998, -23.596, -23.121, -22.819, -22.347]\n",
    "Marchetti_phi = 10 ** np.array([-4.123, -3.558, -3.032, -2.698, -2.451, -2.320, -2.268, -2.071, -2.047, -2.058,\n",
    "                 -2.031, -2.099, -1.858, -1.946])\n",
    "\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Patel_mag = [-27.693, -26.674, -25.695, -24.684, -23.721, -22.664]\n",
    "Patel_phi = 10 ** np.array([-3.789, -3.018, -2.590, -2.501, -2.802, -1.660])\n",
    "plt.errorbar(Patel_mag+5.0*np.log10(Hubble_h), Patel_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Patel et al. 2013')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.subplot(426).set_yticklabels([])\n",
    "plt.subplot(426).set_ylabel('')\n",
    "Marchetti_mag = [-26.597, -26.222, -25.731, -25.342, -24.946, -24.505,\n",
    "                -24.066, -23.698, -23.257, -22.841, -22.452, -22.046, -21.620]\n",
    "Marchetti_phi = 10 ** np.array([-3.584, -3.074, -2.665, -2.246, -2.020,\n",
    "                               -1.786, -1.671, -1.713, -1.707, -1.601, -1.649,\n",
    "                               -1.492, -1.636])\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Dye_mag = [-26.287, -25.574, -24.838, -24.107, -23.421, -22.679, -21.986]\n",
    "Dye_phi = 10 ** np.array([-3.410, -2.872, -2.591, -2.508, -2.263, -1.966, -1.927])\n",
    "plt.errorbar(Dye_mag+5.0*np.log10(Hubble_h), Dye_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Dya et al. 2010')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(427)\n",
    "Marchetti_mag = [-24.274, -23.888, -23.522, -23.043, -22.633, -22.208, -21.764,\n",
    "                 -21.409, -21.019, -20.568, -20.129]\n",
    "Marchetti_phi = 10 ** np.array([-3.606, -2.985, -2.545, -2.422, -2.149, -2.093,\n",
    "                               -2.013, -2.096, -2.083, -1.919, -1.996])\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Negrello_mag = [-24.750, -24.278, -23.551, -22.719, -21.975, -21.238, -20.498, -19.731]\n",
    "Negrello_phi = 10 ** np.array([-3.688, -3.592, -2.816, -2.267, -1.990, -1.883, -1.656, -1.388])\n",
    "plt.errorbar(Negrello_mag+5.0*np.log10(Hubble_h), Negrello_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Negrello et al. 2013')\n",
    "\n",
    "fig.delaxes(axes[-1,-1]) \n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.xlabel('mAB')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "#plt.savefig('plots/IR_mini_tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowlim_list = [-25.3, -25.3, -23.8]\n",
    "uplim_list = [-29, -29, -28]\n",
    "\n",
    "row = 2\n",
    "col = 2\n",
    "fig, axes = plt.subplots(row, col, sharey=True, figsize=(9,12))\n",
    "\n",
    "mi = -30.0\n",
    "ma = -20.0\n",
    "binwidth = 0.5\n",
    "NB = int((ma - mi) / binwidth)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    ax = plt.subplot(row, col, i+1)\n",
    "    counts1, binedges1 = np.histogram(mab_IR[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, '-', lw=1.5, label=IR_filter_d[i] + ' (Dale+14)')\n",
    "    \n",
    "    counts1, binedges1 = np.histogram(mab_IR_s[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, '--', lw=1.5, label=IR_filter_d[i] + ' (Safarzadeh+15)')\n",
    "    '''\n",
    "    counts1, binedges1 = np.histogram(mab_IR[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto1, counts1/ ((BoxSize/Hubble_h)**3) / binwidth, '-.', lw=1.5, label=IR_filter_d[i] + ' (Safarzadeh+15)')\n",
    "    '''\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.ylim(2e-5, 2e-2)\n",
    "    plt.xlim(-30.5, -20.5)\n",
    "    ax.tick_params(axis='both', which='both', direction='in')\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{dex}^{-1})$')  # Set the y...\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(222).set_yticklabels([])\n",
    "plt.subplot(222).set_ylabel('')\n",
    "#Marchetti_mag, Marchetti_phi = np.loadtxt('files/Marchetti_PACS160.dat', usecols=(0,1), unpack=True)\n",
    "Marchetti_mag = [-27.811, -27.373, -26.953, -26.573, -26.031, -25.686, -25.271, -24.844,\n",
    "                -24.413, -23.998, -23.596, -23.121, -22.819, -22.347]\n",
    "Marchetti_phi = 10 ** np.array([-4.123, -3.558, -3.032, -2.698, -2.451, -2.320, -2.268, -2.071, -2.047, -2.058,\n",
    "                 -2.031, -2.099, -1.858, -1.946])\n",
    "\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Patel_mag = [-27.693, -26.674, -25.695, -24.684, -23.721, -22.664]\n",
    "Patel_phi = 10 ** np.array([-3.789, -3.018, -2.590, -2.501, -2.802, -1.660])\n",
    "plt.errorbar(Patel_mag+5.0*np.log10(Hubble_h), Patel_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Patel et al. 2013')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "Marchetti_mag = [-26.597, -26.222, -25.731, -25.342, -24.946, -24.505,\n",
    "                -24.066, -23.698, -23.257, -22.841, -22.452, -22.046, -21.620]\n",
    "Marchetti_phi = 10 ** np.array([-3.584, -3.074, -2.665, -2.246, -2.020,\n",
    "                               -1.786, -1.671, -1.713, -1.707, -1.601, -1.649,\n",
    "                               -1.492, -1.636])\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Dye_mag = [-26.287, -25.574, -24.838, -24.107, -23.421, -22.679, -21.986]\n",
    "Dye_phi = 10 ** np.array([-3.410, -2.872, -2.591, -2.508, -2.263, -1.966, -1.927])\n",
    "plt.errorbar(Dye_mag+5.0*np.log10(Hubble_h), Dye_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Dya et al. 2010')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('mAB')\n",
    "\n",
    "plt.subplot(224).set_yticklabels([])\n",
    "plt.subplot(224).set_ylabel('')\n",
    "Marchetti_mag = [-24.274, -23.888, -23.522, -23.043, -22.633, -22.208, -21.764,\n",
    "                 -21.409, -21.019, -20.568, -20.129]\n",
    "Marchetti_phi = 10 ** np.array([-3.606, -2.985, -2.545, -2.422, -2.149, -2.093,\n",
    "                               -2.013, -2.096, -2.083, -1.919, -1.996])\n",
    "plt.errorbar(Marchetti_mag+5.0*np.log10(Hubble_h), Marchetti_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Marchetti et al. 2016')\n",
    "\n",
    "Negrello_mag = [-24.750, -24.278, -23.551, -22.719, -21.975, -21.238, -20.498, -19.731]\n",
    "Negrello_phi = 10 ** np.array([-3.688, -3.592, -2.816, -2.267, -1.990, -1.883, -1.656, -1.388])\n",
    "plt.errorbar(Negrello_mag+5.0*np.log10(Hubble_h), Negrello_phi*Hubble_h*Hubble_h*Hubble_h, lw=1.0, marker='o', ls='none',label='Negrello et al. 2013')\n",
    "\n",
    "#fig.delaxes(axes[-1,-1]) \n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.xlabel('mAB')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "#plt.savefig('plots/FIR-mini.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_SF = np.loadtxt('files/alpha.dat', usecols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dale_template = np.loadtxt('files/spectra.0.00AGN.dat', unpack=True)\n",
    "lambda_IR = Dale_template[0] * 1e4 #convert from micron to Angstrom\n",
    "delta_lambda_IR = lambda_IR[1:1496] - lambda_IR[0:1495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ldust = (spectra - spectra_dusty)\n",
    "w = np.where(wavelength < 912)[0]\n",
    "idx_912 = w[-1]\n",
    "delta = wavelength[idx_912+1:6900] - wavelength[idx_912:6899]\n",
    "\n",
    "all_wave = np.unique(np.concatenate((wavelength, lambda_IR)))\n",
    "all_wave.sort(kind='mergesort')\n",
    "UVIR = np.zeros((len(Ldust), len(all_wave)))\n",
    "\n",
    "LIR = []\n",
    "alpha_list = []\n",
    "\n",
    "for i in range(len(Ldust)):\n",
    "    LIR_lambda = Ldust[i][idx_912:6899] * delta\n",
    "    LIR_mentari = sum(LIR_lambda)\n",
    "    '''\n",
    "    if (LIR_mentari < 10**9.5):\n",
    "        LIR_mentari = 10**9.5\n",
    "    '''\n",
    "    if (LIR_mentari > 10**11.6):\n",
    "        LIR_mentari = 10**11.6\n",
    "        \n",
    "    alpha = 10.096 - 0.741 * np.log10(LIR_mentari)\n",
    "    delta_alpha = abs(alpha_SF - alpha)\n",
    "    idx = np.where(delta_alpha==min(delta_alpha))[0]\n",
    "    spectra_IR = 10 ** Dale_template[idx[0]+1] \n",
    "\n",
    "    LIR_dale = sum(spectra_IR[0:1495] * delta_lambda_IR)\n",
    "    scaling = LIR_mentari / LIR_dale\n",
    "    alpha_list.append(alpha_SF[idx[0]])\n",
    "    spectra_IR_dale = spectra_IR * scaling \n",
    "    \n",
    "    new_spectra = np.interp(all_wave, wavelength, spectra_dusty[i])\n",
    "    new_IR = np.interp(all_wave, lambda_IR, spectra_IR_dale)\n",
    "    all_spec = new_spectra + new_IR\n",
    "    UVIR[i] = all_spec\n",
    "    LIR.append(spectra_IR_dale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.where(G_history_dusty[0].MetalsColdGas > 0.0)[0]\n",
    "mass1 = np.log10(G_history_dusty[0].MetalsColdGas[w1] * 1.e10 / Hubble_h)\n",
    "\n",
    "w2 = np.where(gas_metals[:,63] / Hubble_h > 0)[0]\n",
    "mass2 = np.log10(gas_metals[:,63][w2] / Hubble_h)\n",
    "\n",
    "#w3 = np.where((metals_sage[:,63] > 0) & (mass_sage[:,63] / Hubble_h > 0))[0]\n",
    "#mass3 = np.log10(mass_sage[:,63][w3] / Hubble_h)\n",
    "\n",
    "#c_mass = np.log10(MassHist_old[0]*MetalHist_old[0] * (1. - rec_frac) / Hubble_h) #final computed mass #final computed mass\n",
    "\n",
    "mi = np.floor(min(mass1)) - 2\n",
    "ma = np.floor(max(mass1)) + 2\n",
    "ma = 14\n",
    "NB = int((ma - mi) / binwidth)\n",
    "\n",
    "#(counts, binedges) = np.histogram(mass, range=(mi, ma), bins=NB)\n",
    "(counts1, binedges1) = np.histogram(mass1, range=(mi, ma), bins=NB)\n",
    "(counts2, binedges2) = np.histogram(mass2, range=(mi, ma), bins=NB)\n",
    "#(counts3, binedges3) = np.histogram(mass3, range=(mi, ma), bins=NB)\n",
    "\n",
    "# Set the x-axis values to be the centre of the bins\n",
    "#xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "xaxeshisto1 = binedges1[:-1] + 0.5 * binwidth\n",
    "xaxeshisto2 = binedges2[:-1] + 0.5 * binwidth\n",
    "#xaxeshisto3 = binedges3[:-1] + 0.5 * binwidth\n",
    "\n",
    "#plt.plot(xaxeshisto, counts / (BoxSize/Hubble_h)**3 / binwidth, 'k-', label='sage')\n",
    "#plt.plot(xaxeshisto3, counts3 / (BoxSize/Hubble_h)**3 / binwidth, 'g:', label='mentari-sage')\n",
    "plt.plot(xaxeshisto1, counts1/ (BoxSize/Hubble_h)**3 / binwidth, 'r-', label='dusty-sage')\n",
    "plt.plot(xaxeshisto2, counts2/ (BoxSize/Hubble_h)**3 / binwidth, 'b:', label='mentari-dustysage')\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.axis([5.0, 10.0, 1.0e-6, 1.0e-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given_metals = np.log10(G_history[0].MetalsStellarMass/G_history[0].StellarMass)\n",
    "given_metals = np.log10(G_history_dusty[0].MetalsStellarMass * 1e10/ Hubble_h)\n",
    "given_mass = np.log10(G_history_dusty[0].StellarMass * 1e10/ Hubble_h)\n",
    "\n",
    "w = np.where(Mass[:,63] > 0)[0]\n",
    "computed_metals_new = np.log10(Metals[:,63][w] * Mass[:,63][w]/ Hubble_h)\n",
    "computed_mass_new = np.log10(Mass[:,63][w]/ Hubble_h)\n",
    "'''\n",
    "w = np.where(MassHist_old[26] > 0)[0]\n",
    "computed_metals_old = np.log10(MetalHist_old[26][w])\n",
    "computed_mass_old = np.log10(MassHist_old[26][w])\n",
    "'''\n",
    "w = np.where(given_mass > 8)\n",
    "plt.plot(given_mass[w], given_metals[w], '.', label='dusty sage')\n",
    "\n",
    "w = np.where(computed_mass_new > 8)\n",
    "plt.plot(computed_mass_new[w], computed_metals_new[w], '.', label='new model')\n",
    "\n",
    "#plt.plot(computed_mass_old, computed_metals_old, '.', label='old model')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$\\log_{10} M_{\\mathrm{stars}}\\ (M_{\\odot})$')  # and the x-axis labels\n",
    "plt.ylabel('Stellar Metallicity')\n",
    "#plt.savefig('old_metals_z1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(mass_dusty[:,63] == max(mass_dusty[:,63]))[0]\n",
    "mass_dusty_new = list(mass_dusty[w] / Hubble_h)\n",
    "metals_dusty_new = list(metals_dusty[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(mass_sage[:,63] == max(mass_sage[:,63]))[0]\n",
    "mass_sage_new = list(mass_sage[w] / Hubble_h)\n",
    "metals_sage_new = list(metals_sage[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.asarray([0.0124, 0.0246, 0.0491, 0.1037, 0.1871, 0.2120, 0.2399, 0.2709, 0.3054, 0.3438, 0.3864, 0.4335, 0.4856, 0.5430, 0.6062, 0.6756, 0.7517, 0.8349, 0.9259, 1.0249, 1.1327, 1.2496, 1.3763, 1.5131, 1.6606, 1.8192, 1.9895, 2.1717, 2.3662, 2.5734, 2.7934, 3.0265, 3.2726, 3.5318, 3.8038, 4.0886, 4.3856, 4.6944, 5.0144, 5.3488, 5.6849, 6.0337, 6.3901, 6.7531, 7.1215, 7.4940, 7.8694, 8.2464, 8.6238, 9.0004, 9.3750, 9.7463, 10.1133, 10.4750, 10.8303, 11.1783, 11.5181, 11.8490, 12.1702, 12.4811, 12.7810, 13.0695, 13.3459, 13.6098])\n",
    "lookbacktime = sorted((np.array([13.6098]*len(age)) - age) * 1.e9)\n",
    "\n",
    "tau_head_ISM = 0.3\n",
    "tau_head_ISM_2 = 0.65\n",
    "tau_head_BC = 1\n",
    "tau_head_BC_2 = 0.3\n",
    "eta_BC = -0.7\n",
    "eta_BC_2 = -1.3\n",
    "eta_ISM = -0.7\n",
    "eta_ISM_2 = -1.4\n",
    "time_BC = 10**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra, spectra_dusty  = generate_SED(0,age, mass_dusty, metals_dusty, \n",
    "                                    tau_head_BC, tau_head_ISM_2, eta_BC, eta_ISM_2, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra_2, spectra_dusty_2  = generate_SED(0,age, mass_dusty, metals_dusty, \n",
    "                                    tau_head_BC, tau_head_ISM_2, eta_BC, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra_3, spectra_dusty_3  = generate_SED(0,age, mass_dusty, metals_dusty, \n",
    "                                    tau_head_BC_2, tau_head_ISM, eta_BC, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra_5, spectra_dusty_5  = generate_SED(0,age, mass_dusty, metals_dusty, \n",
    "                                    tau_head_BC, tau_head_ISM, eta_BC, eta_ISM_2, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength, spectra_4, spectra_dusty_4  = generate_SED(0,age, mass_dusty, metals_dusty, \n",
    "                                    tau_head_BC, tau_head_ISM, eta_BC_2, eta_ISM, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(mass_dusty[:,63]),max(mass_sage[:,63]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_dusty_all, spectra_dusty_all = generate_SED(0,age, mass_dusty, metals_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_sage_all, spectra_sage_all = generate_SED(0,age, mass_sage, metals_sage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wave_IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(age, np.log10(mass_new[0]), label = \"mentari\")\n",
    "#plt.plot(age, np.log10(mass_old), label= \"old model\")\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$\\mathrm{Age}\\ \\mathrm{Myr}$')\n",
    "plt.ylabel(r'$\\log \\mathrm{M_*} \\mathrm{(M_\\odot)}$')\n",
    "#plt.savefig('masshist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(age, np.log10(metals_new[0]/mass_new[0]), label = \"mentari\")\n",
    "#plt.plot(age, np.log10(metals_old), label= \"old model\")\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$\\mathrm{Age}\\ \\mathrm{Myr}$')\n",
    "plt.ylabel(r'$\\mathrm{Stellar}\\ \\mathrm{metallicity}$')\n",
    "#plt.savefig('metalhist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mentari as mtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoxSize = 62.5\n",
    "Hubble_h = 0.73\n",
    "\n",
    "firstfile = 0\n",
    "lastfile = 1\n",
    "directory = 'mini-millennium/' #change this to the output directory of sage\n",
    "filename = 'model'\n",
    "redshift = [127.000, 79.998, 50.000, 30.000, 19.916, 18.244, 16.725, 15.343, 14.086, 12.941, 11.897, 10.944, 10.073, 9.278, 8.550, 7.883, 7.272, 6.712, 6.197, 5.724, 5.289, 4.888, 4.520, 4.179, 3.866, 3.576, 3.308, 3.060, 2.831, 2.619, 2.422, 2.239, 2.070, 1.913, 1.766, 1.630, 1.504, 1.386, 1.276, 1.173, 1.078, 0.989, 0.905, 0.828, 0.755, 0.687, 0.624, 0.564, 0.509, 0.457, 0.408, 0.362, 0.320, 0.280, 0.242, 0.208, 0.175, 0.144, 0.116, 0.089, 0.064, 0.041, 0.020, 0.000]\n",
    "#redshift = [127.000, 79.998, 50.000, 30.000, 19.916, 18.244, 16.725, 15.343, 14.086, 12.941, 11.897, 10.944, 10.073, 9.278, 8.550, 7.883, 7.272, 6.712, 6.197, 5.724, 5.289, 4.888, 4.520, 4.179, 3.866, 3.576, 3.308, 3.060, 2.831, 2.619, 2.422, 2.239, 2.070, 1.913, 1.766, 1.630, 1.504, 1.386]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MassHist_old, MetalHist_old = mtr.build_history(redshift, firstfile, lastfile, directory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_frac = 0.43\n",
    "c_mass = MassHist_old[0] * (1. - rec_frac) / Hubble_h #final computed mass\n",
    "w = np.where(c_mass == max(c_mass))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_old, spectra_old = mtr.generate_SED(lookbacktime, MassHist_old[:,w], MetalHist_old[:,w]) #wavelength in Angstorm, spectra in Lsun/Angstorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot the spectra:\n",
    "\n",
    "ax = plt.subplot2grid((1,1), (0,0))\n",
    "#divider = make_axes_locatable(ax)\n",
    "ax.plot(np.array(wavelength), spectra[0] * np.array(wavelength), lw=0.5, label='no dust')\n",
    "ax.plot(np.array(wavelength), spectra_dusty[0] * np.array(wavelength), lw=0.5, label='dusty')\n",
    "\n",
    "#ax.plot(np.array(wavelength_sage), spectra_sage[0] * np.array(wavelength_sage), lw=0.5, label='sage')\n",
    "#ax.plot(np.array(wavelength_old), spectra_old[0] * np.array(wavelength_old), lw=0.5, label='sage')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel(r'$\\lambda\\ (\\AA) $')\n",
    "ax.set_ylabel(r'log $\\lambda L_{\\lambda} (L_{\\odot})$')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "#plt.savefig('SED-massive.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_old = mtr.mab(wavelength_old, spectra_old, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_new = mtr.mab(wavelength_new, spectra_new, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metallicity = Metals / Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_all_new, spectra_all_new = generate_SED_v2(0, age, Mass, Metallicity) #wavelength in Angstorm, spectra in Lsun/Angstorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f generate_SED_v2 generate_SED_v2(0, age, Mass, Metallicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(Mass[:,63] > 0)[0]\n",
    "spectra_all_new_v2 = spectra_all_new[w] / Hubble_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_chabrier = compute_mab(wavelength, spectra_dusty / Hubble_h , filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_2 = compute_mab(wavelength, spectra_dusty_2 / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_3 = compute_mab(wavelength, spectra_dusty_3 / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_4 = compute_mab(wavelength, spectra_dusty_4 / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_dusty_5 = compute_mab(wavelength, spectra_dusty_5 / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_sage_dusty = compute_mab(wavelength, spectra_sage_dusty / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_list_old = mtr.mab(wavelength_all_old, spectra_all_old / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the Luminosity Function vs Kelvin et al. 2013\n",
    "\n",
    "hubble=0.73\n",
    "label = ['Mu', 'Mg', 'Mr', 'Mi', 'Mz']\n",
    "color = ('grey', 'black', 'blue', 'red', 'green', 'purple')\n",
    "\n",
    "mi = -30.0\n",
    "ma = -15.0\n",
    "binwidth = 0.3\n",
    "NB = int((ma - mi) / binwidth)\n",
    "M = np.arange(mi, ma, 0.01)\n",
    "\n",
    "plt.figure()\n",
    "ax =plt.subplot(111)\n",
    "\n",
    "# Observations from Kelvin et al. 2013\n",
    "'''\n",
    "# SDSS u\n",
    "Mstar = -18.53\n",
    "alpha1 = -0.91\n",
    "phistar1 = 0.00964\n",
    "alpha2 = 1.25\n",
    "phistar2 = 0.00146\n",
    "xval = 10.0 ** (0.4*(Mstar-M))\n",
    "yval = 0.4 * np.log(10.0) * (phistar1 * xval ** (alpha1+1) + phistar2 * xval ** (alpha2+1)) * np.exp(-xval)      \n",
    "plt.plot(M, yval, '--', c=color[1], lw=0.5, label='Kelvin et al (2013)')\n",
    "\n",
    "# SDSS g\n",
    "Mstar = -20.28\n",
    "alpha1 = -1.29\n",
    "phistar1 = 0.00351\n",
    "alpha2 = 0.06\n",
    "phistar2 = 0.00488\n",
    "xval = 10.0 ** (0.4*(Mstar-M))\n",
    "yval = 0.4 * np.log(10.0) * (phistar1 * xval ** (alpha1+1) + phistar2 * xval ** (alpha2+1)) * np.exp(-xval)          \n",
    "plt.plot(M, yval, '--', c=color[2],lw=0.5)\n",
    "\n",
    "# SDSS r\n",
    "Mstar = -20.90\n",
    "alpha1 = -1.13\n",
    "phistar1 = 0.00451\n",
    "alpha2 = 0.53\n",
    "phistar2 = 0.00301\n",
    "xval = 10.0 ** (0.4*(Mstar-M))\n",
    "yval = 0.4 * np.log(10.0) * (phistar1 * xval ** (alpha1+1) + phistar2 * xval ** (alpha2+1)) * np.exp(-xval)          \n",
    "plt.plot(M, yval, '--', c=color[3],lw=0.5)\n",
    "\n",
    "# SDSS i\n",
    "Mstar = -21.45\n",
    "alpha1 = -1.35\n",
    "phistar1 = 0.00220\n",
    "alpha2 = -0.09\n",
    "phistar2 = 0.00487\n",
    "xval = 10.0 ** (0.4*(Mstar-M))\n",
    "yval = 0.4 * np.log(10.0) * (phistar1 * xval ** (alpha1+1) + phistar2 * xval ** (alpha2+1)) * np.exp(-xval)              \n",
    "plt.plot(M, yval, '--', c=color[4], lw=0.5, label='Kelvin et al (2013)')\n",
    "\n",
    "# SDSS z\n",
    "Mstar = -21.78\n",
    "alpha1 = -1.46\n",
    "phistar1 = 0.0014\n",
    "alpha2 = -0.26\n",
    "phistar2 = 0.00505\n",
    "xval = 10.0 ** (0.4*(Mstar-M))\n",
    "yval = 0.4 * np.log(10.0) * (phistar1 * xval ** (alpha1+1) + phistar2 * xval ** (alpha2+1)) * np.exp(-xval)                \n",
    "plt.plot(M, yval, '--', c=color[5], lw=0.5)\n",
    "'''\n",
    "twomass_k = [0]\n",
    "ug = [1, 2]\n",
    "sdss_r = [3]\n",
    "sdss_i = [4]\n",
    "sdss_z = [5]\n",
    "iz=[4, 5]\n",
    "sdss =[1,2,3,4,5]\n",
    "\n",
    "for i in twomass_k:\n",
    "    \n",
    "    counts, binedges = np.histogram(mab_dusty[i], range=(mi, ma), bins=NB)\n",
    "    xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "    plt.plot(xaxeshisto, counts/ ((BoxSize/Hubble_h)**3) / binwidth, c=color[i], lw=1.0)\n",
    "        \n",
    "counts, binedges = np.histogram(mab_dusty[i], range=(mi, ma), bins=NB)\n",
    "xaxeshisto = binedges[:-1] + 0.5 * binwidth\n",
    "plt.plot(xaxeshisto, counts/ ((BoxSize/Hubble_h)**3) / binwidth, c=color[i], lw=1.0, label='dusty-sage')\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel(r'$\\phi\\ (\\mathrm{Mpc}^{-3}\\ \\mathrm{dex}^{-1})$')  # Set the y...\n",
    "plt.xlabel(r'$M$')\n",
    "plt.ylim(2e-4, 1e-1)\n",
    "plt.xlim(-24, -16.5)\n",
    "ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "leg = plt.legend(loc='upper left', numpoints=1, labelspacing=0.1)\n",
    "leg.draw_frame(False)  # Don't want a box frame\n",
    "for t in leg.get_texts():  # Reduce the size of the text\n",
    "    t.set_fontsize('medium')\n",
    "#plt.savefig('k.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MassHist = list(mass_dusty / Hubble_h)\n",
    "MetalHist = list(metals_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau(tau_head, eta, wavelength):\n",
    "    return(tau_head * (wavelength/5500)**eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_list = compute_mab(wavelength, total_lum_dusty / Hubble_h, filter_list, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_nodust = compute_mab(wavelength, total_lum / Hubble_h, filter_list, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScaleRad = G_history_dusty[0].DiskRadius * 1e6 / Hubble_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area(rad):\n",
    "    return (2 * np.pi * rad**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(G_history_dusty[0].ColdDust > 0)[0]\n",
    "ScaleRad = G_history_dusty[0].DiskRadius[w] * 1e6 / Hubble_h #in pc\n",
    "fdust = G_history_dusty[0].ColdDust[w] / G_history_dusty[0].MetalsColdGas[w]\n",
    "Zgas = G_history_dusty[0].MetalsColdGas[w] / G_history_dusty[0].ColdGas[w]\n",
    "rad = 3 * ScaleRad #MilkyWay\n",
    "halfrad = 1.68 * ScaleRad\n",
    "twohalfrad = 2 * halfrad\n",
    "ColdGas = G_history_dusty[0].ColdGas[w] * 1e10 / Hubble_h\n",
    "ColdDust = G_history_dusty[0].ColdDust[w] * 1e10 / Hubble_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(mass_dusty[:,63] > 0)[0]\n",
    "print(max(mass_dusty[w,63]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScaleRad = rad[w[1],63] * 1e6 / Hubble_h\n",
    "threerad = 3 * ScaleRad\n",
    "halfrad = 1.68 * ScaleRad\n",
    "twohalfrad = 2 * ScaleRad\n",
    "dust_mass = dust[w[1],63] / Hubble_h\n",
    "gas_mass = gas[w[1],63] / Hubble_h\n",
    "metals_mass = gas_metals[w[1],63] / Hubble_h\n",
    "\n",
    "fdust = dust_mass / metals_mass\n",
    "Zgas = metals_mass / gas_mass\n",
    "\n",
    "\n",
    "ScaleRad_kpc = rad[w[1],63] * 1e3 / Hubble_h #in kpc\n",
    "threerad_kpc = 3 * ScaleRad_kpc #MilkyWay\n",
    "halfrad_kpc = 1.68 * ScaleRad_kpc\n",
    "twohalfrad_kpc = 2 * halfrad_kpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdust_MW = 0.33\n",
    "Zsun = 0.0189\n",
    "Sigma_MW = 85 #Msun/pc2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau_BC(ColdDust, ColdGas, rad):\n",
    "    '''\n",
    "    ColdDust in Msun\n",
    "    ColdGas in Msun\n",
    "    rad in Mpc\n",
    "    '''\n",
    "    \n",
    "    fdust = ColdDust / ColdGas\n",
    "    ScaleRad = rad * 1e6 #convert to pc\n",
    "    halfrad = 1.68 * ScaleRad \n",
    "    \n",
    "    fdust_MW = 0.33\n",
    "    Zsun = 0.0189\n",
    "    Sigma_MW = 85 #Msun/pc2 \n",
    "    \n",
    "    area = compute_area(halfrad)\n",
    "    Sigma_gas = ColdGas / area\n",
    "    w = np.where(Sigma_gas < Sigma_MW)[0]\n",
    "    if Sigma_gas < Sigma_MW:\n",
    "        Sigma_gas = Sigma_MW\n",
    "    tau_BC = (fdust * Sigma_gas) / (fdust_MW * Zsun * Sigma_MW)\n",
    "    Sigma_BC = np.log10(fdust * Sigma_gas * 1e6) #kpc\n",
    "    \n",
    "    return tau_BC, Sigma_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_BC_a, Sigma_BC_a = compute_tau_BC(ColdDust, ColdGas, rad)\n",
    "#tau_BC_b, Sigma_BC_b = compute_tau_BC(ColdDust, ColdGas, halfrad)\n",
    "#tau_BC_c, Sigma_BC_c = compute_tau_BC(ColdDust, ColdGas, twohalfrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in iterate_trees(SAM_choice, directory, firstfile, lastfile):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau_ISM(ColdDust, rad):\n",
    "    '''\n",
    "    ColdDust in Msun\n",
    "    rad in Mpc\n",
    "    '''\n",
    "    \n",
    "    ScaleRad = rad * 1e3 #convert to kpc\n",
    "    halfrad = 1.68 * ScaleRad\n",
    "    Sigma_dust_Trayford = [4.088, 4.351, 4.579, 4.823, 5.057, 5.292, 5.528, 5.765, 6.001, 6.234, 6.470, 6.704, 6.941, 7.177, 7.416]\n",
    "    tau_head_Trayford = [0.031, 0.059, 0.078, 0.129, 0.203, 0.308, 0.467, 0.647, 0.838, 1.065, 1.235, 1.475, 1.571, 1.645, 1.806]\n",
    "\n",
    "    area = compute_area(halfrad)\n",
    "    Sigma_dust = np.log10(ColdDust / area)\n",
    "    tau_ISM = np.interp(Sigma_dust, Sigma_dust_Trayford, tau_head_Trayford)\n",
    "    \n",
    "    return Sigma_dust, tau_ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eta_ISM(ColdDust, rad):\n",
    "    '''\n",
    "    ColdDust in Msun\n",
    "    rad in Mpc\n",
    "    '''\n",
    "    ScaleRad = rad * 1e3 #convert to kpc\n",
    "    halfrad = 1.68 * ScaleRad\n",
    "    \n",
    "    Sigma_dust_Trayford = [4.116, 4.354, 4.588, 4.822, 5.061, 5.293, 5.533, 5.763, 6.003, 6.236, 6.469, 6.706, 6.943, 7.181, 7.411]\n",
    "    eta_ISM_Trayford = [-1.379, -1.357, -1.334, -1.243, -1.170, -1.062, -0.922, -0.778, -0.668, -0.570, -0.506, -0.453, -0.381, -0.318, -0.307]\n",
    "    area = compute_area(halfrad)\n",
    "    Sigma_dust = np.log10(ColdDust / area)\n",
    "    eta_ISM = np.interp(Sigma_dust, Sigma_dust_Trayford, eta_ISM_Trayford)\n",
    "    \n",
    "    return Sigma_dust, eta_ISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_BC_a, Sigma_BC_a = compute_tau_BC(dust_mass, gas_mass, threerad)\n",
    "tau_BC_b, Sigma_BC_b = compute_tau_BC(dust_mass, gas_mass, halfrad)\n",
    "tau_BC_c, Sigma_BC_c = compute_tau_BC(dust_mass, gas_mass, twohalfrad)\n",
    "\n",
    "Sigma_tau_a, tau_ISM_a = compute_tau_ISM(dust_mass, threerad_kpc)\n",
    "Sigma_tau_b, tau_ISM_b = compute_tau_ISM(dust_mass, halfrad_kpc)\n",
    "Sigma_tau_c, tau_ISM_c = compute_tau_ISM(dust_mass, twohalfrad_kpc)\n",
    "\n",
    "Sigma_eta_a, eta_ISM_a = compute_eta_ISM(dust_mass, threerad_kpc)\n",
    "Sigma_eta_b, eta_ISM_b = compute_eta_ISM(dust_mass, halfrad_kpc)\n",
    "Sigma_eta_c, eta_ISM_c = compute_eta_ISM(dust_mass, twohalfrad_kpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sigma_BC_a, tau_BC_a)\n",
    "print(Sigma_BC_b, tau_BC_b)\n",
    "print(Sigma_BC_c, tau_BC_c)\n",
    "print(tau_BC_a, tau_ISM_a, eta_ISM_a)\n",
    "print(tau_BC_b, tau_ISM_b, eta_ISM_b)\n",
    "print(tau_BC_c, tau_ISM_c, eta_ISM_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where((G_history_dusty[0].DiskRadius > 0) & (G_history_dusty[0].ColdDust > 0))[0]\n",
    "\n",
    "ScaleRad_kpc = G_history_dusty[0].DiskRadius[w] * 10**3 / Hubble_h #in kpc\n",
    "rad_kpc = 3 * ScaleRad_kpc #MilkyWay\n",
    "halfrad_kpc = 1.68 * ScaleRad_kpc\n",
    "twohalfrad_kpc = 2 * halfrad_kpc\n",
    "\n",
    "ColdDust = G_history_dusty[0].ColdDust[w] * 1e10 / Hubble_h\n",
    "\n",
    "area_kpc = compute_area(rad_kpc)\n",
    "sigma = np.log10(ColdDust / area_kpc)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_tau_a, tau_ISM_a = compute_tau_ISM(ColdDust, rad_kpc)\n",
    "Sigma_tau_b, tau_ISM_b = compute_tau_ISM(ColdDust, halfrad_kpc)\n",
    "Sigma_tau_c, tau_ISM_c = compute_tau_ISM(ColdDust, twohalfrad_kpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_eta_a, eta_ISM_a = compute_eta_ISM(ColdDust, rad_kpc)\n",
    "Sigma_eta_b, eta_ISM_b = compute_eta_ISM(ColdDust, halfrad_kpc)\n",
    "Sigma_eta_c, eta_ISM_c = compute_eta_ISM(ColdDust, twohalfrad_kpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_head_ISM_list = np.interp(Sigma_dust, Sigma_dust_tau, tau_head_Trayford) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_ISM_list = np.interp(Sigma_dust, Sigma_dust_tau, eta_ISM_Trayford) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Sigma_dust, bins=20, range=(0, 8), density='True', label=r'$\\Sigma_\\mathrm{dust,ISM}$')\n",
    "plt.hist(Sigma_dust_BC, bins=20, range=(0, 8), density='True', label=r'$\\Sigma_\\mathrm{dust,BC}$')\n",
    "plt.legend(loc=0)\n",
    "plt.savefig('plots/hist_sigma.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where(mass_dusty[:,63] > 1e11)[0]\n",
    "fdust = G_history_dusty[0].ColdDust[w] / G_history_dusty[0].MetalsColdGas[w]\n",
    "Zgas = G_history_dusty[0].MetalsColdGas[w] / G_history_dusty[0].ColdGas[w]\n",
    "rad = 3 * G_history_dusty[0].DiskRadius[w] * 10**6 / Hubble_h\n",
    "area = np.pi * rad**2\n",
    "Sigma_gas = G_history_dusty[0].ColdGas[w] * 1e10 / Hubble_h / area\n",
    "w = np.where(Sigma_gas < 85)[0]\n",
    "Sigma_gas[w] = 85\n",
    "\n",
    "#computing tau_head_BC\n",
    "fdust_MW = 0.33\n",
    "Zsun = 0.0189\n",
    "Sigma_MW = 85 #Msun/(pc2)\n",
    "Sigma_dust_BC = np.log10(fdust * Zgas * Sigma_gas * 1e6)\n",
    "tau_head_BC_list = fdust * Zgas * Sigma_gas / (fdust_MW * Zsun * Sigma_MW)\n",
    "\n",
    "Sigma_dust_tau = [4.088, 4.351, 4.579, 4.823, 5.057, 5.292, 5.528, 5.765, 6.001, 6.234, 6.470, 6.704, 6.941, 7.177, 7.416]\n",
    "tau_head_Trayford = [0.031, 0.059, 0.078, 0.129, 0.203, 0.308, 0.467, 0.647, 0.838, 1.065, 1.235, 1.475, 1.571, 1.645, 1.806]\n",
    "\n",
    "rad_kpc = 3 * G_history_dusty[0].DiskRadius[w] * 10**3 / Hubble_h\n",
    "area_kpc = 2 * np.pi * rad_kpc**2\n",
    "\n",
    "fdg = G_history_dusty[0].ColdDust[w] / G_history_dusty[0].ColdGas[w]\n",
    "sigma_gas = G_history_dusty[0].ColdGas[w] * 1e10 / Hubble_h / area_kpc\n",
    "w = np.where(Sigma_gas < 85 * 1.e6)[0]\n",
    "sigma_gas[w] = 85 * 1.e6\n",
    "sigma_dust_a = np.log10(fdg * sigma_gas)\n",
    "Sigma_dust_b = np.log10(G_history_dusty[0].ColdDust[w] * 1e10 / Hubble_h / area_kpc)\n",
    "\n",
    "#computing tau_head_ISM\n",
    "tau_head_ISM_list = np.interp(Sigma_dust, Sigma_dust_tau, tau_head_Trayford) \n",
    "\n",
    "print(tau_head_BC_list, tau_head_ISM_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColdDust = G_history_dusty[0].ColdDust[w] * 1e10 / Hubble_h\n",
    "\n",
    "area_kpc = compute_area(rad_kpc)\n",
    "sigma = np.log10(ColdDust / area_kpc)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sigma_dust_BC, Sigma_dust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.asarray([0.0124, 0.0246, 0.0491, 0.1037, 0.1871, 0.2120, 0.2399, 0.2709, 0.3054, 0.3438, 0.3864, 0.4335, 0.4856, 0.5430, 0.6062, 0.6756, 0.7517, 0.8349, 0.9259, 1.0249, 1.1327, 1.2496, 1.3763, 1.5131, 1.6606, 1.8192, 1.9895, 2.1717, 2.3662, 2.5734, 2.7934, 3.0265, 3.2726, 3.5318, 3.8038, 4.0886, 4.3856, 4.6944, 5.0144, 5.3488, 5.6849, 6.0337, 6.3901, 6.7531, 7.1215, 7.4940, 7.8694, 8.2464, 8.6238, 9.0004, 9.3750, 9.7463, 10.1133, 10.4750, 10.8303, 11.1783, 11.5181, 11.8490, 12.1702, 12.4811, 12.7810, 13.0695, 13.3459, 13.6098])\n",
    "lookbacktime = sorted((np.array([13.6098]*len(age)) - age) * 1.e9)\n",
    "\n",
    "#tau_head_ISM = 0.3\n",
    "#tau_head_ISM_2 = 0.5\n",
    "#tau_head_BC = 1\n",
    "eta_BC = -0.7\n",
    "#eta_BC_2 = -1.3\n",
    "#eta_ISM = -0.7\n",
    "time_BC = 10**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_a, spectra_a, spectra_dusty_a = generate_SED(1, age, mass_dusty[w], metals_dusty[w], \n",
    "             tau_BC_a, tau_ISM_a, eta_BC, eta_ISM_a, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_b, spectra_b, spectra_dusty_b = generate_SED(1, age, mass_dusty[w], metals_dusty[w], \n",
    "             tau_BC_b, tau_ISM_b, eta_BC, eta_ISM_b, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_c, spectra_c, spectra_dusty_c = generate_SED(1, age, mass_dusty[w], metals_dusty[w], \n",
    "             tau_BC_c, tau_ISM_c, eta_BC, eta_ISM_c, time_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = np.array(tau_head_ISM_list) * (wavelength/5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tau(tau_head, eta, wavelength):\n",
    "    tau\n",
    "    return(tau_head * (wavelength/5500)**eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectra_dusty_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.where((mass_dusty[:,63] / Hubble_h >5.8e10) & (mass_dusty[:,63] / Hubble_h <6.3e10))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = (age[1:63] - age[0:62]) * 1e9\n",
    "delta_mass = mass_dusty[w[2]][1:63] - mass_dusty[w[2]][0:62]\n",
    "sfr = delta_mass / Hubble_h / delta_t\n",
    "age_new = age[1:63] \n",
    "lookback = (np.array([13.6098]*len(age_new)) - age_new) * 1.e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lookback, sfr, '.-', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.2\n",
    "\n",
    "sfr_tau =5*e**-(gamma*age)\n",
    "lookback_new = (np.array([13.6098]*len(age)) - age) * 1.e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "ax = plt.subplot(211)\n",
    "ax.set_xticklabels([])\n",
    "plt.plot(age, sfr_tau, 'k', lw=1.0)\n",
    "plt.xlim(0, 14)\n",
    "ax.tick_params(axis='both', direction='in')\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.plot(age_new, sfr, 'k', lw=1.0)\n",
    "plt.xlim(0, 14)\n",
    "plt.xlabel(\"Age of Universe (Gyr)\")\n",
    "ax.tick_params(axis='both', direction='in')\n",
    "\n",
    "fig.text(0.05, 0.4, 'SFR ($\\mathrm{M_\\odot / yr}$)', rotation=90)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig('plots/sfr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavelength, (spectra[w][2] - spectra_dusty[w][2]) / Hubble_h)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim(1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_ISM = compute_tau(tau_head_ISM, eta_ISM, wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavelength, 1.086*tau_ISM)\n",
    "#plt.xlim(800, 40000)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luminosity_distance(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "filterlist = ['Sdss_u', 'Sdss_r']\n",
    "F = read_filters()\n",
    "mab_list = []\n",
    "for i in range(len(filterlist)):\n",
    "    filters_wave = eval('F.' + filterlist[i] + '_wave')\n",
    "    filters = eval('F.' + filterlist[i])\n",
    "    upper = simps(filters * filters_wave, filters_wave)\n",
    "    lower = simps(filters / filters_wave, filters_wave)\n",
    "    lambda_eff = np.sqrt(upper/lower)\n",
    "    print(lambda_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_effective_wavelength(filter):\n",
    "    filters_wave = eval('F.' + filter + '_wave')\n",
    "    filters = eval('F.' + filter)\n",
    "    upper = simps(filters * filters_wave, filters_wave)\n",
    "    lower = simps(filters / filters_wave, filters_wave)\n",
    "    lambda_eff = np.sqrt(upper/lower)\n",
    "    \n",
    "    return(lambda_eff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
